[
    {
        "module_number": 1,
        "module_name": "Fundamentals of System Hardware Script",
        "file_name": "Module 1 Fundamentals of System Hardware Script.docx",
        "transcript": [
            {
                "title": "Introduction 1.2",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Overview 1.3",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Definition 1.4",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Types of Computers 1.5",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Inside a Computer 1.6",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "What\u2019s Common Between Them 1.7",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "The CPU 1.9",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Machine Language 1.10",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Instruction Set 1.11",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Fetch-Execute Cycle 1.12",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Memory 1.13",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "The Hierarchy 1.14",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Secondary Storage 1.17",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "HDD vs. SDD 1.18",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Networking 1.19",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Physical Connections 1.20",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Packets 1.21",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            },
            {
                "title": "Layers We Commonly Use 1.22",
                "data": [
                    "So in this module we looked at the definition of computer. We looked at types of computers we saw the insides of the computers. We talked about what each component of the computer does and the commonalities between those components we looked at system bus and how all those components communicate with each other we talked about how the CPU work specifically with the fetch and execute cycle.",
                    "We talked about the memory higher key how things on the top are much faster but much more expensive and things on the bottom are much slower but much cheaper. We talked about hard disks and the difference between solid state this drives and hard disk drives and then we got into computer networking and how data travels around the world.",
                    "So I hope you followed and I hope you enjoyed that see you next week.",
                    "",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 2,
        "module_name": "Positional Number Systems",
        "file_name": "Module 2 Positional Number Systems.docx",
        "transcript": [
            {
                "title": "Conclusion 1.23",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Counting in Base 10 2.1",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Counting in Base 5 2.2",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Counting in Base 2 2.4",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Counting in Base 16 2.5",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Equivalent Representation 2.6",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Decimal to Base B 3.3",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Let's start with this position here, with the digit in with the weight 256. Should that be a zero or a one? I believe most of you said that it must be a 0. Let's try to argue why this is indeed right, or the only possible value for this digit. Actually, it makes a lot of sense because if we would put a 1 here, only this digit would give us the weight of 256 which is greater than the total weight we're trying to represent, the total value of 75. So, there can't be a one in this position. This position, therefore, must be a 0. Actually, not only this position of 256, but all digits that their weight is greater than 75: the 128, 256, 512, and so on. All of these digits must be a zero, right? The real question is what would be the value with the rest of the digits. So, all of them together should represent or should add up to the value of seventy five. And, let's try to go over them one by one and figure out whether they should be a 1 or a 0. We\u2019ll go over them from left to right, starting with this digit here, with a 64.",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Binary & Hexadecimal Base Conversations 3.4",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Binary and Hexadecimal 3.5",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Addition 4.1",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "So, for example, let's try to add 325 to 692, two decimal numbers. We start, I think third grade, our teacher said start with the ones digit. So, we add 5 and 2, we get 7. And then, for the tens digit we had 2 tens and 9 tens, that would give us 11 tens, which would, 11 tens would be grouped into 100 and an additional ten. That's why we write 1 in the tens, and carry over an additional hundred. Then we have 100 plus 300 plus 600, it adds up to 10 hundreds. And we have, therefore, 0 for the ten hundreds and 1 for the thousand because these 10 hundreds were grouped into one group of a thousand. So, we have 0 hundreds and 1 carried to the thousands, which would then be dropped down, and all together we have 1017.",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Okay, now that we know how to add numbers in different number systems, let's see how we can subtract numbers in a different number system. Again, let's start with decimal for practice, and then try to generalize it to other number systems as well. So, let's try to subtract 427 minus 192 decimal. So, we start with the ones right. 7 minus 2 that would give us a 5, then we try to subtract 2 minus 9 and that's a problem because we can\u2019t subtract 9 from 2, so we would need to borrow an additional 10 tens, actually in this case. So, instead of having 2 tens, we'll have 12 tens, and that by splitting the hundred, the 4 hundreds into 3 hundred and 10 tens. That would leave us with 3 hundred and 10 tens additional 2 tens that would give a 312 ten. So, instead of saying 42 tens or 420, we say 312 tens. Then we have these 12 tens minus 9 that would give us a 3 and 300 minus 1, that would give us a 2. So 427 minus 192 is 235.",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "Signed Numbers 5.1",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": " Two\u2019s Complement 5.2",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            },
            {
                "title": "So we know that if we add 26 to negative 26, they should add up to this 1 and eight 0s. So let's try to figure out negative 26, digit by digit. So zero plus what, would give us the zero? Zero, obviously. One plus what, would give us a zero? It could either be zero or one, obviously, it's not a zero. So it must be a one, but not only that it gives us a 0, it also carries another 2 to the next position. So 1 plus 0 plus what, would give us a zero? That's 1 plus 1 would give us a 0 and another carry over of 1. 1 plus 1 plus what, would give us a zero? 1 plus 1 plus 0 would give us a 0, with the carry over; 1 plus 1 plus 0 with the carry over. 1 plus 0 plus what, would give us a zero? 1 plus 0 plus 1 would give us a 0, right? It's basically a ten so it's a 0 and the carryover of another 1; 1 plus 0 plus 1 and 1 plus 0 plus 1. So, taking this number here of 11100110, this thing here, that's the 8-bits Two\u2019s Complement representation of negative 26.",
                "data": [
                    "Okay, let's do another example working with Two\u2019s Complement. So let's take this number here, 00101101, represented in a 2-bit Two\u2019s Complement, that's the representation method for this number, and try to figure out what's its decimal equivalent, what this number basically represents. So, since it a starts with a zero, we know that it is a positive number. Then, this representation method says that the first (k minus 1), seven bits, basically represent its value. So if we add 32 and 8 and 4 and 1, we get 45 and this number is basically the decimal 45. ",
                    "Let's take a look at this number here, 11101010, again in an 8-bit Two\u2019s Complement representation and try to figure out what its decimal representation. In this case, since it starts with the one, it's not a positive number. But this a presentation method is not \u2018Sign and Magnitude\u2019 that we can just figure out the value of the lower seven bits and say that it is negative of this value. Since it's a Two\u2019s Complement representation method, we should figure out the absolute value of this number in a different way. ",
                    "",
                    "So let's use the second property that the sum of a number and its additive value, additive inverse, is 2 to the power of 8. In this case, we know that, we don't know what these values are but we know that this number here is some kind of a negative something. Let\u2019s say negative X. So 11101010 is some negative X. and we\u2019ll try to find what positive X. is, so we can know what the absolute value of this number. So once again, we're trying to figure out what number is missing there, to be the additive inverse of the number that we have no idea what it is. But since the additive inverse would be positive and positive numbers are much easier to figure out their value, we can then figure out what the value of the negative number. So once again, let's try to find what's the additive inverse of our input of this 11101010. So 0 plus what, would give us a zero? 0 plus 0. 1 plus what, would give us a zero? Plus 1 with a carry over. 1 plus 0 plus 1, and then another carry over. 1 plus 1 plus 0 with the carry over. 1 plus 0 plus 1, and 1 plus 1 plus 0. And 1 plus 0 plus 0, and 1 plus 1 plus 0. ",
                    "So, basically we got that our number is 11101010 but its additive inverse, its absolute value, it's positive corresponding value is 00010110. And this number is very easy to figure out its value because we just have to add the weights of each digit. So we have a 2 plus a 4 plus 16, and that adds up to 22. So this number here is positive 22, which implies that the negative number we had before is negative 22. So this number 11101010 in an 8-bit Two\u2019s Complement representation, it represents the number negative 22 decimal.",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 3,
        "module_name": "Hello World Script",
        "file_name": "Module 3 Hello World Script.docx",
        "transcript": [
            {
                "title": "Two\u2019s Complement 5.3",
                "data": [
                    "Ok so we have a program that can be executed by the computer. It looks as a sequence of zeroes and ones that represent instructions for the CPU to execute. These instructions are very low level they can add things multiply move data from one place to another jump to another position. Very simple set of instructions. We are not going to program with zeroes and ones. This kind of programming language is called machine language that is obviously understood by the machine by the CPU by a computer. We are going to program and write and implement our algorithms using a high level language. There are a lot of high level languages we are going to write in C++ but there are also Java Python C# and C and Pascal and Scheme and a lot of high level languages. A program let\u2019s say in C++ would not look as a sequence of zeroes and ones it would look more like  that. Which is a text in English contains the English alphabet you can see we don\u2019t understand exactly what it does but you can see it has a text Hello World it has some English words you can probably recognize like main and include and return and stuff like that. So we write in something that is much closer to our natural language not zeroes and ones. But then the computer doesn\u2019t understand this type of language. So we need to translate this code here into a machine language code. This kind of translation or this process of translating a high level language into language the machine the computer can understand is called compilation or a build process and we lucky for us it is an automated process since even high level languages are very strict and we have to follow the rules accurately. And automated process can just take the code in the programming language and translate it into machine language. So we just have to start this process and then our computer will be able to execute the program we write in the high level language. I will show you how we do that as we write our first program.",
                    " ",
                    "First C++ Program 1.4 ",
                    "Ok so let\u2019s start to write our first C++ program. Let\u2019s make it easy let\u2019s write a program that reads from the user to numbers and just prints what the sum of these numbers are. So we want to interact with the user something like that we would first ask the user please enter two numbers separated by a space. The user would enter for example 7 and 5 and then the program would respond 7 plus 5 equals 12. Let\u2019s see how we write it in C++.",
                    "",
                    " First C++ Program Screencast 1.5 ",
                    "Ok so here at the screen you can see the implementation of the program that reads two numbers and prints what their sum is. Let\u2019s take a closer look at this implementation let\u2019s first look at the file here. We see that there is text in English plain English this program reads two integers from the user and prints their sum. Will hold the first input will hold the second input. That\u2019s English and that obviously is not C++ and you can see that we can write text in English for documentation purposes. So other programmers can understand what we are trying to say. These are called comments the syntax for writing a comment basically saying for the compiler to ignore that\u2019s for only humans to read is starting the comment by slash star and ending the comment by slash stair slash. And then in between you can write whatever text you want the compiler would just ignore it. You can write in how many lines that you wish you can write your text. For this kind of a comment that starts with slash star and ends with a star slash. A different kind of a comment uses two slashes basically telling the compiler to ignore whatever is written from this point to the end of the line. You can\u2019t break the lines for this type of comment. So we typically write some information describing what the purpose of the program is what the purpose of some lines of code if they have like a complicated goal that they are trying to do. So they are commenting it using one of these syntaxes. So let\u2019s ignore the comments they are not compiled they are not translated to machine language they are not understood by compiler at all. If you see we have int main with a empty parentheses and then you have an open curly brace and the closed curly brace basically saying that a program is everything that is enclosed in these two curly braces. We always start our program with int main and empty parentheses and then inside a block of curly braces we write our program. We also have these two lines at the beginning include iostream using namespace std. Make sure you write exactly as it appears here with that hashtag and the less than greater than symbols and the semi colon over here. It makes a lot of difference for the compiler. I am not getting into the details of what these two lines are doing just now maybe I will talk about it later or in later modules. I am not also explaining too much of the int main basically does but each program would start with these two lines for now that\u2019s what we need to know and with a header of the int main curly braces. One more thing though and that with the return zero. That is something that is common for each program. Another important thing you can see here is that each line of code here ends with a semi colon. That basically says for the compiler that the statement the expression the instruction ends here. So you see that each line here ends with a semi colon you have one two three four five six seven eight instructions. We write them in eight separate lines but for the compiler all that matters are the semi colons. If it was up to the compiler we can write all our program in one single line just separating with semi colons. So for the compiler writing the code something like that in one long line is perfectly fine. The compiler would know that the first instruction  ends here the second instruction ends here and the third instruction ends here. We write it in a different lines in separate lines because it is easier for us humans to understand and see the structure of the code. But for the compiler the semi colon is what ends an instruction that\u2019s why we have to make sure we end each one of our instructions with a semi colon the compiler won\u2019t tolerate an instruction that doesn\u2019t end with a semi colon. Another thing I want to say before we start here is that in C++ we have to declare we have to state ahead what are the variables we are going to use. What are the datas that we need inside our memory. So in this case we said we need num1 num2 and sum. We also have to say what is the type of each of them. So basically we say num1 would be a variable that is an int instance for integer meaning that num1 would hold an integer value. Num2 is a variable of type int that would hold another integer value and sum is a third variable again of type int that would hold another integer value. We also said for other programmers that num1 is used to hold the first input num2 is used to hold the second input and sum would be used to hold the sum. But that\u2019s only for us to understand. For the compiler we are saying that this program would use three variables num1 num2 and sum all are type int. You can see here we have cout leave the cout but you can see that we have out basically saying we want to output it and we basically say we want to output we want to print out the text please enter two numbers separated by a space. We want to continue printing end l basically saying basically stands for end line. We want to break the line so we want to print this text and break the line. Then cin basically saying getting an input from the user into num1 and into num2. So after printing the announcement please enter two numbers separated by space we are reading whatever the user enter into these two variables num1 and num2. After we have the user\u2019s input inside our num1 and num2 we are saying put into the sum variable the value of num1 plus num2. This equal sign here stands for an assignment we want to assign this value here of num1 plus num2 into the variable sum. So our program would first print the instruction for the user to enter two numbers separated by a space. Then it would read num1 and num2 it would read the two inputs into these two variables and then sum would be assigned with the value of the sum of num1 and num2. Eventually we will just cout we will print out to the screen once again. Num1 the value of num1 the text plus the value of num2 the text equals and the value of sum followed by a break line line break. That\u2019s basically what we are doing here in order to see that it really behaves as we expected we need to compile it we need to build this program and then to run it. So by now I hope you have your IDE already installed if you are using Windows you are probably using Visual Studio if you are using MAC probably you are using Xcode but other IDEs are also fine. If you don\u2019t have an IDE installed please do it right after this module. For Xcode just press this play button it builds a program. Here build succeeded and here we have our program starting to execute first it says please enter two numbers separated by a space I will just type five space seven space five. When I press enter I get the response seven plus five equals twelve and it also says that program ended with exit code zero that\u2019s what the return zero basically does. So it works as we expected which is good I want us to note a few things here now that we get the structure of the code. For example I can do cin num1 semi colon cin num2 semi colon in two separate lines still the execution would be the same. So cin doesn\u2019t really mind if we do it in two different lines or in one line it would still behave the same. I prefer doing it this way. We\u2019ll talk in more detail about the behavior of cin in one of the future module. Another thing regarding cout I can have multiple cout for example please enter two numbers let\u2019s end it and cout separated by a space in a different line. Try to guess if you think that the output would be in one line or in two lines here in the execution. Hope you are guessing it I am building it in the mean time. And you can see that even though the cout is broken into two separate instructions it is still printed in one line and that\u2019s because we didn\u2019t break the line we didn\u2019t say print kind of an enter. If I would say please enter two numbers endl and then cout separated by a space then it would be just one second. Then it would be printed in two lines but if I am just splitting the cout into two lines without breaking the line in the output it would still be in one single line of output. Again let\u2019s just bring it back to how it was before. So that\u2019s one more thing I wanted to point out here. One last thing is that let\u2019s take a look at this output statement here. You see that we didn\u2019t do something like cout num1 plus num2 equals sum. If we would do that it would just send a text num1 plus num2 equals sum. But we want to print the value inside num1 variable and inside num2 variable and inside the sum variable. That\u2019s why we are not printing num1 num2 and sum as texts inside quotes we are printing num1 on its own that would print the value of num1 and then we are printing the text plus and then we are printing the value of the variable num2 followed by the text equal and then we are printing the value of the variable sum. One last thing to note here if we want to concatenate print outs we always use the double less than symbols so cout start with num1 continue printing this text continuing printing num2 continuing printing the text equal continuing printing sum and continuing printing line break line. Yeah I think this gives us an idea how C++ program is structured and the basics of interacting with the user using cout and cin."
                ]
            }
        ]
    },
    {
        "module_number": 4,
        "module_name": "Data Types and Expressions Part 1",
        "file_name": "Module 4 Data Types and Expressions Part 1.docx",
        "transcript": [
            {
                "title": "Data Types and Expressions 1.2",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            },
            {
                "title": "Data Types and Expressions 1.3",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            },
            {
                "title": "Data Types and Expressions 1.4",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            },
            {
                "title": "The int Data Type 2.1",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            },
            {
                "title": "The int Data Type 2.2",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            },
            {
                "title": "Weeks and Days 2.6",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            },
            {
                "title": "Weeks and Days 2.7",
                "data": [
                    "Let\u2019s implement this program so first let\u2019s ask the user to enter the number of days they travel so cout. And then please enter number of days you traveled. Let\u2019s break the line end line. And then let\u2019s read whatever the user enters into a variable. Since it is number of days int is the type we want to use here. We first have to declare this variable so int. And then we have to decide what the name of this variable would be. In my previous examples I just used x y z whatever because they had no meaning just to show you the syntax of integers. But here in this program this variable would be used to store some significant kind of data. It is going to store the days user traveled. So let\u2019s give it meaningful name in this case I would name it days traveled. But then I can\u2019t have a variable name days traveled made of two words. So I need to somehow create a single word that would be made of more than one word in it. So there are a few common conventions on how to do that. One way is to separate the word something like underscore symbol something like that into days traveled. Another convention could be something like to capitalize the beginning of each word days traveled and then easily you can see what this long sequence of characters basically mean. Third convention is to start capitalizing only from the second word so the first d is lower case then the t for the travel is uppercase. For variable names the common C++ convention is something like that. Capitalizing each word starting with the second word so int days traveled this is the variable name we will choose here. And then cin days traveled that\u2019s the variable we are going to read into. Now that we have the input from the user so we ask the user to enter the number of days they traveled. We read these days into this variable now we should calculate how many full weeks and what\u2019s the remaining days. So just as I spoke it the variable names should be probably full weeks and remaining days. So let\u2019s declare two additional variables one I would name full weeks. Note that I am using this convention lower case f upper case w. And remaining days once again lower case r upper case d. You can also note that when you declare more than one variable of the same type you can do it in a single line of code and separate the variables with a comma. In this case I declared two variables in this line both of them are of type int. One named full weeks and the other remaining days. So right here after we have the number of days traveled in order to figure out the number of full weeks we said we should div it by 7. So we do full weeks equals days traveled div 7 right. That\u2019s the number of full weeks and the remaining days would be numbers of days traveled mod 7. So remaining days equals day traveled mod 7. So I am using the percent sign here. So I have these values so now that I have calculated the amount of full days and how many days are remaining I can output the message to the user cout. And I want it to be in the format of in the case of the input of 19 19 days or two weeks and five days. So let\u2019s start with days traveled which would be our 19 and then days are which would be full weeks as a string. And then the remaining days days. After that we want to break the line something like that. So we have in the case of the input of 19 19 days are two weeks and five days. This should be fine let\u2019s execute it and see if we need to make some minor changes. So I am compiling it I am just pressing the play button here. And please enter the number of days you traveled. I entered 19 and then it says 19 days are two weeks and five days. There is a spacing issue here and actually it makes sense because we printed days traveled and then the text days are with no spaces. So if we want to space 19 and days we have to add a space over here. We should also add a space here before the two so there would be 19 space days space are space and then two and then again we need to add a space here and a space here and also space here. Now it should look better let\u2019s execute it. Once again let\u2019s enter the input 19 and then it would say 19 days are two weeks and five days. Seems to work perfectly fine. One last thing that I want to update here is the use of 7 here. So as you can see we have the variables days traveled full weeks remaining days. They are all variables with type int they are all data of type int they are all integers. And then we use 7 here and 7 here are also integers because they are C++ literals but this 7 is not an arbitrary numbers. We use 7 because 7 is the number of days in a week. A lot of times we prefer to define our own constant to represent this value. To make our code more clear. We typically define constants above the main. We can define it just next to the variables as well. Maybe later on we will discuss what\u2019s the difference of the location where we define our variables and constants. But for now let\u2019s define constants before the main. So up here I will do constant int and now I want to define a constant that the value would be 7. I am trying to think what I should name this integer constant and typically I choose the name by what it represents by describe what it represents. So 7 represents the number of days in a week. For constants the common convention for constant name is using all upper case and separating t he words with underscore. So it would be days in a week and then I would set it to 7. So not like variables where we define the variable all lower case and separate the words starting with the second one with upper case. In constants we have a different naming convention where we type the entire text as uppercase and separates the words with underscore. So days in a week equals 7 and then instead of just typing 7 here I would just divide it by days in a week and I would mod it by days in a week. So when someone reads our code now they can see that full weeks are basically days traveled div the numbers of days in a week. And the remaining days are days traveled mod the number of days in a week. There is no supposed to be any effect on the execution just instead of writing the literal 7 we define our own constant with the value of 7. So here when we type 19 we just get once again two weeks then five days. "
                ]
            }
        ]
    },
    {
        "module_number": 4,
        "module_name": "Data Types and Expressions Part 2",
        "file_name": "Module 4 Data Types and Expressions Part 2.docx",
        "transcript": [
            {
                "title": "Weeks and Days Implementation 2.8",
                "data": [
                    "Ok let\u2019s go ahead and implement this program. So first thing we do is we ask the user to enter the radius of the circle. So cout please enter the radius so break the line here. And then let\u2019s read the user\u2019s radius for that let\u2019s first declare a variable. Since radius could be a real number with a fractional part let\u2019s use the double type for this variable. And if we are thinking how to name it this is going to store the radius maybe we should just name it radius. So double radius that\u2019s a variable we created here and let\u2019s read into the radius variable. So we got the input from the user now we should calculate the area of this circle. So let\u2019s add a variable to store the area and I will just name it area. And then after having the radius let\u2019s set area to be pi times radius squared. So pi is 3.14 times radius times radius. Something like that so pi that\u2019s radius squared. So we have the area calculated after that we should announce to the user that the area of a circle is whatever the value of the variable area is. So let\u2019s start cout and then let\u2019s print the text the area of a circle with radius of space here. And then write the value of the variable radius and then the word is once again space before and after and the value of the variable area let\u2019s end the line. So we have the area of a circle with the radius of the value of the variable radius is the value of the variable area. Basically output statement we want to make here let\u2019s test it see if we didn\u2019t make any mistakes. Please enter the radius 2.6 and then it says the area of a circle with radius of 2.6 is 21.2264. One thing I would change here is instead of hardcoding the value 3.14 let\u2019s create a constant with this value and give it a meaningful name. In this case we probably should name it pi. Because 3.14 stands for pi so up here above the main we will create a constant of type double named pi and the value would be 3.14. After we have that instead of writing 3.14 we should just use pi the constant name and that would be replaced by 3.14 and that makes our code be more readable. So we say that area equals pi times radius squared. Let\u2019s test it once again although it is not supposed to behave any differently. So the radius is 2.6 and then it prints that the area of a circle radius is 2.6 is once again 21.2264. So looks very good though that is not really an accurate value here for the area that\u2019s because the value of pi I gave here 3.14 is not very good estimation for pi. So we could either have pi figure out what the more accurate value of pi and just change our constant. Or we could add or use some predefined value of pi. So pi is not a pre defined constant in C++ but then there are extensions for C++ language that we can use these extensions include the value of pi. In order to use these extensions we use the pound include statement just as we\u2019ve done up here pound include iostream. Baiscally we are extending the C++ language to include some more abilities of io input output. Actually cout and cin are not built in operators in C++ they are not defined not predefined in C++. If we won\u2019t have this include iostream cout and cin won\u2019t work we will have compilation errors for trying to execute them. In order to use cout and cin we need to extend our language to include some iostream capabilities and then cout and cin are defined then we can definitely use them. Same thing with pi in order to have the predefined constant pi and to be able to use it we need to include to extend our language. So let\u2019s add some include statement here and the name of the library that we are going to use the pi constant and some other mathematical capabilities is called cmath. So if we include cmath that would have predefined pi constant in it so we won\u2019t need to define this constant on our own. We can just use the cmath pi constant that is already defined. The only thing is that it is not called pi p i as we could expect this is called m underscore pi math pi. So area is now math pi times radius times radius. This math pi constant is much more accurate than 3.14 and if we execute it again the program will now we are expecting to get a better approximation for the area it would be slightly different than 21.2264. Let\u2019s try it out if we have 2.6 the area now is 21.2372 slightly different probably better result here. Yes so we basically read the radius from the user we use the pi constant in order to calculate the area and then we output the statement saying what the area is. ",
                    "",
                    "Type Casting 2.1 ",
                    "Ok now that we have a few types in hand int float double let\u2019s see what happens in some cases when we try to mix these types kind of together. So for example we have four variable two if type int x one and x two and two of type double y one and y two. If we assign x one with 6 and y one with 6.7 that would a perfectly valid because six is an int literal x one is an int variable and assigning int into an int makes perfect sense. Same thing when we are assigning y one is 6.7 6.7 is a double literal y one is a double variable and the assigning a double into a double is very reasonable. But what would happen if we try to assign y two with a value of 6? When we try to assign an integer 6 an integer literal into a double y two which is a double variable. Formally this expression is legal we cannot assign an int to a double or something that is not of the same type. The compiler won\u2019t say anything it will figure out a way to get over that but formally what we need to do is basically to convert the representation of the integer 6 to the representation of the same or the equivalent value in the representation of a double. The syntax to do that is called casting converting the representation of data to one type to an equivalent value in another type. The syntax is the new type included in parentheses in this case double followed by the value we want to convert into double. So the expression double 6 would convert the integer 6 into a representation or an equivalent representation in a type double. And this expression double 6 is of type double and then assigning double 6 into y two is a legal assigning. It is a assigning a double into a double variable. So when a casting is evaluated basically the representation of this data is converted from one representation method to another. From 32 bit 2\u2019s complement representation of an integer in this case into a 64 floating point representation of a double. And this conversion is done by syntax of casting into a double of the value 6. It would be interesting to think what would happen if we tried to convert or to cast 6.7 the double 6.7 into representation of int. Int of 6.7 but then we can\u2019t really keep the value or the converted value equivalent to 6.7 because integers cannot represent a fractional part or a number a real number 6.7. So what would the compiler convert the double 6.7 to? To what integer would it be converted? So we can try it out but I will tell you what is going to happen. It is basically going to remove the fractional part and convert 6.7 to a 6 in this case. So this assigning x two equals int of 6.7 would assign the integer x two to the value of the integer 6. ",
                    "",
                    "Expressions 2.2 ",
                    "Let\u2019s take a look at another example of what happens when we mix the types. For example if we cout 5 divided by 2 so since 5 and 2 are both integers the dividing operators has the meaning of div. As we said that when slash comes between two integers that means div. If we do 5.0 divided 2.0 the dividing operator has the meaning of real division because when a dividing operator comes between two doubles it has the meaning of a real division. So the first cout would print 2 because 5 div 2 is 2. The second cout would print 2.5 because 5.0 divided by 2.0 is 2.5. What do you think would happen if we divide 5.0 by 2? When we try to divide a double by an integer. What meaning would the divider operator have in this case? Actually I don\u2019t know maybe it has the meaning of the div maybe it has the meaning of a real division or maybe it could even be an error. So it is not an error you can relax here the compiler when we have mixed types in an expression the compiler would try to resolve the issue of the mixing types and would try to make casting of the arguments to state where the two operands would be of the same type. The casting would be what we call implicit cast casting that do not lose any accuracy in this case converting an int to a double never loses any accuracy. Because every integer could be represented as a double not the other way around right not every double can be represented as an integer some accuracy can be lost. Just as when we converted 6.7 into an integer the .7 got lost there. But converting 2 to a double that is a conversion that can be done implicitly can be done without losing any accuracy. So the compiler would try to match the types of these operands 5.0 and 2 in this case casts 2 to a double and then the dividing operator would be in the meaning of real division. So this cout would also print 2.5. Another thing I want to show you here what happens if we assign x to the value of 5 divided by 2. Obviously no issue 5 and 2 are both integers the dividing operator is div in this case so 5 div 2 is 2 and x as an integer gets the value of 2. But what will happen if we assign y to 5 div 2? Y is a double right so do you think that in this case 5 divided by 2 would be 2.5 and y would get the value 2.5 or 5 div 2 5 divided by 2 would still be 2 and y would be assigned to 2. You can try it out but I will tell you what would happen. So an assignment expression has two steps in its evaluation. First step is evaluating the right hand side after we get this value the value is assigned to the variable. And the first step doesn\u2019t take into account what\u2019s the type of the variable we are going to assign the second step. The first step just evaluates the right hand side in this case evaluating 5 divided by 2. And once again since 5 and 2 are both integers the dividing comes in a form of div. So when we are evaluating the right hand side here 5 divided by 2 would result to 2 the integer 2. But then we are trying to assign the integer 2 to the variable of type double formally we should have casted the integer 2 to a double but the compiler would do it for us so y would get the double of the value 2. What we would like to write as the literal 2.0. So y would be the double 2 in this case."
                ]
            },
            {
                "title": "Float and Double Data Types 1.3",
                "data": [
                    "Ok let\u2019s go ahead and implement this program. So first thing we do is we ask the user to enter the radius of the circle. So cout please enter the radius so break the line here. And then let\u2019s read the user\u2019s radius for that let\u2019s first declare a variable. Since radius could be a real number with a fractional part let\u2019s use the double type for this variable. And if we are thinking how to name it this is going to store the radius maybe we should just name it radius. So double radius that\u2019s a variable we created here and let\u2019s read into the radius variable. So we got the input from the user now we should calculate the area of this circle. So let\u2019s add a variable to store the area and I will just name it area. And then after having the radius let\u2019s set area to be pi times radius squared. So pi is 3.14 times radius times radius. Something like that so pi that\u2019s radius squared. So we have the area calculated after that we should announce to the user that the area of a circle is whatever the value of the variable area is. So let\u2019s start cout and then let\u2019s print the text the area of a circle with radius of space here. And then write the value of the variable radius and then the word is once again space before and after and the value of the variable area let\u2019s end the line. So we have the area of a circle with the radius of the value of the variable radius is the value of the variable area. Basically output statement we want to make here let\u2019s test it see if we didn\u2019t make any mistakes. Please enter the radius 2.6 and then it says the area of a circle with radius of 2.6 is 21.2264. One thing I would change here is instead of hardcoding the value 3.14 let\u2019s create a constant with this value and give it a meaningful name. In this case we probably should name it pi. Because 3.14 stands for pi so up here above the main we will create a constant of type double named pi and the value would be 3.14. After we have that instead of writing 3.14 we should just use pi the constant name and that would be replaced by 3.14 and that makes our code be more readable. So we say that area equals pi times radius squared. Let\u2019s test it once again although it is not supposed to behave any differently. So the radius is 2.6 and then it prints that the area of a circle radius is 2.6 is once again 21.2264. So looks very good though that is not really an accurate value here for the area that\u2019s because the value of pi I gave here 3.14 is not very good estimation for pi. So we could either have pi figure out what the more accurate value of pi and just change our constant. Or we could add or use some predefined value of pi. So pi is not a pre defined constant in C++ but then there are extensions for C++ language that we can use these extensions include the value of pi. In order to use these extensions we use the pound include statement just as we\u2019ve done up here pound include iostream. Baiscally we are extending the C++ language to include some more abilities of io input output. Actually cout and cin are not built in operators in C++ they are not defined not predefined in C++. If we won\u2019t have this include iostream cout and cin won\u2019t work we will have compilation errors for trying to execute them. In order to use cout and cin we need to extend our language to include some iostream capabilities and then cout and cin are defined then we can definitely use them. Same thing with pi in order to have the predefined constant pi and to be able to use it we need to include to extend our language. So let\u2019s add some include statement here and the name of the library that we are going to use the pi constant and some other mathematical capabilities is called cmath. So if we include cmath that would have predefined pi constant in it so we won\u2019t need to define this constant on our own. We can just use the cmath pi constant that is already defined. The only thing is that it is not called pi p i as we could expect this is called m underscore pi math pi. So area is now math pi times radius times radius. This math pi constant is much more accurate than 3.14 and if we execute it again the program will now we are expecting to get a better approximation for the area it would be slightly different than 21.2264. Let\u2019s try it out if we have 2.6 the area now is 21.2372 slightly different probably better result here. Yes so we basically read the radius from the user we use the pi constant in order to calculate the area and then we output the statement saying what the area is. ",
                    "",
                    "Type Casting 2.1 ",
                    "Ok now that we have a few types in hand int float double let\u2019s see what happens in some cases when we try to mix these types kind of together. So for example we have four variable two if type int x one and x two and two of type double y one and y two. If we assign x one with 6 and y one with 6.7 that would a perfectly valid because six is an int literal x one is an int variable and assigning int into an int makes perfect sense. Same thing when we are assigning y one is 6.7 6.7 is a double literal y one is a double variable and the assigning a double into a double is very reasonable. But what would happen if we try to assign y two with a value of 6? When we try to assign an integer 6 an integer literal into a double y two which is a double variable. Formally this expression is legal we cannot assign an int to a double or something that is not of the same type. The compiler won\u2019t say anything it will figure out a way to get over that but formally what we need to do is basically to convert the representation of the integer 6 to the representation of the same or the equivalent value in the representation of a double. The syntax to do that is called casting converting the representation of data to one type to an equivalent value in another type. The syntax is the new type included in parentheses in this case double followed by the value we want to convert into double. So the expression double 6 would convert the integer 6 into a representation or an equivalent representation in a type double. And this expression double 6 is of type double and then assigning double 6 into y two is a legal assigning. It is a assigning a double into a double variable. So when a casting is evaluated basically the representation of this data is converted from one representation method to another. From 32 bit 2\u2019s complement representation of an integer in this case into a 64 floating point representation of a double. And this conversion is done by syntax of casting into a double of the value 6. It would be interesting to think what would happen if we tried to convert or to cast 6.7 the double 6.7 into representation of int. Int of 6.7 but then we can\u2019t really keep the value or the converted value equivalent to 6.7 because integers cannot represent a fractional part or a number a real number 6.7. So what would the compiler convert the double 6.7 to? To what integer would it be converted? So we can try it out but I will tell you what is going to happen. It is basically going to remove the fractional part and convert 6.7 to a 6 in this case. So this assigning x two equals int of 6.7 would assign the integer x two to the value of the integer 6. ",
                    "",
                    "Expressions 2.2 ",
                    "Let\u2019s take a look at another example of what happens when we mix the types. For example if we cout 5 divided by 2 so since 5 and 2 are both integers the dividing operators has the meaning of div. As we said that when slash comes between two integers that means div. If we do 5.0 divided 2.0 the dividing operator has the meaning of real division because when a dividing operator comes between two doubles it has the meaning of a real division. So the first cout would print 2 because 5 div 2 is 2. The second cout would print 2.5 because 5.0 divided by 2.0 is 2.5. What do you think would happen if we divide 5.0 by 2? When we try to divide a double by an integer. What meaning would the divider operator have in this case? Actually I don\u2019t know maybe it has the meaning of the div maybe it has the meaning of a real division or maybe it could even be an error. So it is not an error you can relax here the compiler when we have mixed types in an expression the compiler would try to resolve the issue of the mixing types and would try to make casting of the arguments to state where the two operands would be of the same type. The casting would be what we call implicit cast casting that do not lose any accuracy in this case converting an int to a double never loses any accuracy. Because every integer could be represented as a double not the other way around right not every double can be represented as an integer some accuracy can be lost. Just as when we converted 6.7 into an integer the .7 got lost there. But converting 2 to a double that is a conversion that can be done implicitly can be done without losing any accuracy. So the compiler would try to match the types of these operands 5.0 and 2 in this case casts 2 to a double and then the dividing operator would be in the meaning of real division. So this cout would also print 2.5. Another thing I want to show you here what happens if we assign x to the value of 5 divided by 2. Obviously no issue 5 and 2 are both integers the dividing operator is div in this case so 5 div 2 is 2 and x as an integer gets the value of 2. But what will happen if we assign y to 5 div 2? Y is a double right so do you think that in this case 5 divided by 2 would be 2.5 and y would get the value 2.5 or 5 div 2 5 divided by 2 would still be 2 and y would be assigned to 2. You can try it out but I will tell you what would happen. So an assignment expression has two steps in its evaluation. First step is evaluating the right hand side after we get this value the value is assigned to the variable. And the first step doesn\u2019t take into account what\u2019s the type of the variable we are going to assign the second step. The first step just evaluates the right hand side in this case evaluating 5 divided by 2. And once again since 5 and 2 are both integers the dividing comes in a form of div. So when we are evaluating the right hand side here 5 divided by 2 would result to 2 the integer 2. But then we are trying to assign the integer 2 to the variable of type double formally we should have casted the integer 2 to a double but the compiler would do it for us so y would get the double of the value 2. What we would like to write as the literal 2.0. So y would be the double 2 in this case."
                ]
            },
            {
                "title": "Float and Double Data Types 1.5",
                "data": [
                    "Ok let\u2019s go ahead and implement this program. So first thing we do is we ask the user to enter the radius of the circle. So cout please enter the radius so break the line here. And then let\u2019s read the user\u2019s radius for that let\u2019s first declare a variable. Since radius could be a real number with a fractional part let\u2019s use the double type for this variable. And if we are thinking how to name it this is going to store the radius maybe we should just name it radius. So double radius that\u2019s a variable we created here and let\u2019s read into the radius variable. So we got the input from the user now we should calculate the area of this circle. So let\u2019s add a variable to store the area and I will just name it area. And then after having the radius let\u2019s set area to be pi times radius squared. So pi is 3.14 times radius times radius. Something like that so pi that\u2019s radius squared. So we have the area calculated after that we should announce to the user that the area of a circle is whatever the value of the variable area is. So let\u2019s start cout and then let\u2019s print the text the area of a circle with radius of space here. And then write the value of the variable radius and then the word is once again space before and after and the value of the variable area let\u2019s end the line. So we have the area of a circle with the radius of the value of the variable radius is the value of the variable area. Basically output statement we want to make here let\u2019s test it see if we didn\u2019t make any mistakes. Please enter the radius 2.6 and then it says the area of a circle with radius of 2.6 is 21.2264. One thing I would change here is instead of hardcoding the value 3.14 let\u2019s create a constant with this value and give it a meaningful name. In this case we probably should name it pi. Because 3.14 stands for pi so up here above the main we will create a constant of type double named pi and the value would be 3.14. After we have that instead of writing 3.14 we should just use pi the constant name and that would be replaced by 3.14 and that makes our code be more readable. So we say that area equals pi times radius squared. Let\u2019s test it once again although it is not supposed to behave any differently. So the radius is 2.6 and then it prints that the area of a circle radius is 2.6 is once again 21.2264. So looks very good though that is not really an accurate value here for the area that\u2019s because the value of pi I gave here 3.14 is not very good estimation for pi. So we could either have pi figure out what the more accurate value of pi and just change our constant. Or we could add or use some predefined value of pi. So pi is not a pre defined constant in C++ but then there are extensions for C++ language that we can use these extensions include the value of pi. In order to use these extensions we use the pound include statement just as we\u2019ve done up here pound include iostream. Baiscally we are extending the C++ language to include some more abilities of io input output. Actually cout and cin are not built in operators in C++ they are not defined not predefined in C++. If we won\u2019t have this include iostream cout and cin won\u2019t work we will have compilation errors for trying to execute them. In order to use cout and cin we need to extend our language to include some iostream capabilities and then cout and cin are defined then we can definitely use them. Same thing with pi in order to have the predefined constant pi and to be able to use it we need to include to extend our language. So let\u2019s add some include statement here and the name of the library that we are going to use the pi constant and some other mathematical capabilities is called cmath. So if we include cmath that would have predefined pi constant in it so we won\u2019t need to define this constant on our own. We can just use the cmath pi constant that is already defined. The only thing is that it is not called pi p i as we could expect this is called m underscore pi math pi. So area is now math pi times radius times radius. This math pi constant is much more accurate than 3.14 and if we execute it again the program will now we are expecting to get a better approximation for the area it would be slightly different than 21.2264. Let\u2019s try it out if we have 2.6 the area now is 21.2372 slightly different probably better result here. Yes so we basically read the radius from the user we use the pi constant in order to calculate the area and then we output the statement saying what the area is. ",
                    "",
                    "Type Casting 2.1 ",
                    "Ok now that we have a few types in hand int float double let\u2019s see what happens in some cases when we try to mix these types kind of together. So for example we have four variable two if type int x one and x two and two of type double y one and y two. If we assign x one with 6 and y one with 6.7 that would a perfectly valid because six is an int literal x one is an int variable and assigning int into an int makes perfect sense. Same thing when we are assigning y one is 6.7 6.7 is a double literal y one is a double variable and the assigning a double into a double is very reasonable. But what would happen if we try to assign y two with a value of 6? When we try to assign an integer 6 an integer literal into a double y two which is a double variable. Formally this expression is legal we cannot assign an int to a double or something that is not of the same type. The compiler won\u2019t say anything it will figure out a way to get over that but formally what we need to do is basically to convert the representation of the integer 6 to the representation of the same or the equivalent value in the representation of a double. The syntax to do that is called casting converting the representation of data to one type to an equivalent value in another type. The syntax is the new type included in parentheses in this case double followed by the value we want to convert into double. So the expression double 6 would convert the integer 6 into a representation or an equivalent representation in a type double. And this expression double 6 is of type double and then assigning double 6 into y two is a legal assigning. It is a assigning a double into a double variable. So when a casting is evaluated basically the representation of this data is converted from one representation method to another. From 32 bit 2\u2019s complement representation of an integer in this case into a 64 floating point representation of a double. And this conversion is done by syntax of casting into a double of the value 6. It would be interesting to think what would happen if we tried to convert or to cast 6.7 the double 6.7 into representation of int. Int of 6.7 but then we can\u2019t really keep the value or the converted value equivalent to 6.7 because integers cannot represent a fractional part or a number a real number 6.7. So what would the compiler convert the double 6.7 to? To what integer would it be converted? So we can try it out but I will tell you what is going to happen. It is basically going to remove the fractional part and convert 6.7 to a 6 in this case. So this assigning x two equals int of 6.7 would assign the integer x two to the value of the integer 6. ",
                    "",
                    "Expressions 2.2 ",
                    "Let\u2019s take a look at another example of what happens when we mix the types. For example if we cout 5 divided by 2 so since 5 and 2 are both integers the dividing operators has the meaning of div. As we said that when slash comes between two integers that means div. If we do 5.0 divided 2.0 the dividing operator has the meaning of real division because when a dividing operator comes between two doubles it has the meaning of a real division. So the first cout would print 2 because 5 div 2 is 2. The second cout would print 2.5 because 5.0 divided by 2.0 is 2.5. What do you think would happen if we divide 5.0 by 2? When we try to divide a double by an integer. What meaning would the divider operator have in this case? Actually I don\u2019t know maybe it has the meaning of the div maybe it has the meaning of a real division or maybe it could even be an error. So it is not an error you can relax here the compiler when we have mixed types in an expression the compiler would try to resolve the issue of the mixing types and would try to make casting of the arguments to state where the two operands would be of the same type. The casting would be what we call implicit cast casting that do not lose any accuracy in this case converting an int to a double never loses any accuracy. Because every integer could be represented as a double not the other way around right not every double can be represented as an integer some accuracy can be lost. Just as when we converted 6.7 into an integer the .7 got lost there. But converting 2 to a double that is a conversion that can be done implicitly can be done without losing any accuracy. So the compiler would try to match the types of these operands 5.0 and 2 in this case casts 2 to a double and then the dividing operator would be in the meaning of real division. So this cout would also print 2.5. Another thing I want to show you here what happens if we assign x to the value of 5 divided by 2. Obviously no issue 5 and 2 are both integers the dividing operator is div in this case so 5 div 2 is 2 and x as an integer gets the value of 2. But what will happen if we assign y to 5 div 2? Y is a double right so do you think that in this case 5 divided by 2 would be 2.5 and y would get the value 2.5 or 5 div 2 5 divided by 2 would still be 2 and y would be assigned to 2. You can try it out but I will tell you what would happen. So an assignment expression has two steps in its evaluation. First step is evaluating the right hand side after we get this value the value is assigned to the variable. And the first step doesn\u2019t take into account what\u2019s the type of the variable we are going to assign the second step. The first step just evaluates the right hand side in this case evaluating 5 divided by 2. And once again since 5 and 2 are both integers the dividing comes in a form of div. So when we are evaluating the right hand side here 5 divided by 2 would result to 2 the integer 2. But then we are trying to assign the integer 2 to the variable of type double formally we should have casted the integer 2 to a double but the compiler would do it for us so y would get the double of the value 2. What we would like to write as the literal 2.0. So y would be the double 2 in this case."
                ]
            },
            {
                "title": "Float and Double Data Types 1.6",
                "data": [
                    "Ok let\u2019s go ahead and implement this program. So first thing we do is we ask the user to enter the radius of the circle. So cout please enter the radius so break the line here. And then let\u2019s read the user\u2019s radius for that let\u2019s first declare a variable. Since radius could be a real number with a fractional part let\u2019s use the double type for this variable. And if we are thinking how to name it this is going to store the radius maybe we should just name it radius. So double radius that\u2019s a variable we created here and let\u2019s read into the radius variable. So we got the input from the user now we should calculate the area of this circle. So let\u2019s add a variable to store the area and I will just name it area. And then after having the radius let\u2019s set area to be pi times radius squared. So pi is 3.14 times radius times radius. Something like that so pi that\u2019s radius squared. So we have the area calculated after that we should announce to the user that the area of a circle is whatever the value of the variable area is. So let\u2019s start cout and then let\u2019s print the text the area of a circle with radius of space here. And then write the value of the variable radius and then the word is once again space before and after and the value of the variable area let\u2019s end the line. So we have the area of a circle with the radius of the value of the variable radius is the value of the variable area. Basically output statement we want to make here let\u2019s test it see if we didn\u2019t make any mistakes. Please enter the radius 2.6 and then it says the area of a circle with radius of 2.6 is 21.2264. One thing I would change here is instead of hardcoding the value 3.14 let\u2019s create a constant with this value and give it a meaningful name. In this case we probably should name it pi. Because 3.14 stands for pi so up here above the main we will create a constant of type double named pi and the value would be 3.14. After we have that instead of writing 3.14 we should just use pi the constant name and that would be replaced by 3.14 and that makes our code be more readable. So we say that area equals pi times radius squared. Let\u2019s test it once again although it is not supposed to behave any differently. So the radius is 2.6 and then it prints that the area of a circle radius is 2.6 is once again 21.2264. So looks very good though that is not really an accurate value here for the area that\u2019s because the value of pi I gave here 3.14 is not very good estimation for pi. So we could either have pi figure out what the more accurate value of pi and just change our constant. Or we could add or use some predefined value of pi. So pi is not a pre defined constant in C++ but then there are extensions for C++ language that we can use these extensions include the value of pi. In order to use these extensions we use the pound include statement just as we\u2019ve done up here pound include iostream. Baiscally we are extending the C++ language to include some more abilities of io input output. Actually cout and cin are not built in operators in C++ they are not defined not predefined in C++. If we won\u2019t have this include iostream cout and cin won\u2019t work we will have compilation errors for trying to execute them. In order to use cout and cin we need to extend our language to include some iostream capabilities and then cout and cin are defined then we can definitely use them. Same thing with pi in order to have the predefined constant pi and to be able to use it we need to include to extend our language. So let\u2019s add some include statement here and the name of the library that we are going to use the pi constant and some other mathematical capabilities is called cmath. So if we include cmath that would have predefined pi constant in it so we won\u2019t need to define this constant on our own. We can just use the cmath pi constant that is already defined. The only thing is that it is not called pi p i as we could expect this is called m underscore pi math pi. So area is now math pi times radius times radius. This math pi constant is much more accurate than 3.14 and if we execute it again the program will now we are expecting to get a better approximation for the area it would be slightly different than 21.2264. Let\u2019s try it out if we have 2.6 the area now is 21.2372 slightly different probably better result here. Yes so we basically read the radius from the user we use the pi constant in order to calculate the area and then we output the statement saying what the area is. ",
                    "",
                    "Type Casting 2.1 ",
                    "Ok now that we have a few types in hand int float double let\u2019s see what happens in some cases when we try to mix these types kind of together. So for example we have four variable two if type int x one and x two and two of type double y one and y two. If we assign x one with 6 and y one with 6.7 that would a perfectly valid because six is an int literal x one is an int variable and assigning int into an int makes perfect sense. Same thing when we are assigning y one is 6.7 6.7 is a double literal y one is a double variable and the assigning a double into a double is very reasonable. But what would happen if we try to assign y two with a value of 6? When we try to assign an integer 6 an integer literal into a double y two which is a double variable. Formally this expression is legal we cannot assign an int to a double or something that is not of the same type. The compiler won\u2019t say anything it will figure out a way to get over that but formally what we need to do is basically to convert the representation of the integer 6 to the representation of the same or the equivalent value in the representation of a double. The syntax to do that is called casting converting the representation of data to one type to an equivalent value in another type. The syntax is the new type included in parentheses in this case double followed by the value we want to convert into double. So the expression double 6 would convert the integer 6 into a representation or an equivalent representation in a type double. And this expression double 6 is of type double and then assigning double 6 into y two is a legal assigning. It is a assigning a double into a double variable. So when a casting is evaluated basically the representation of this data is converted from one representation method to another. From 32 bit 2\u2019s complement representation of an integer in this case into a 64 floating point representation of a double. And this conversion is done by syntax of casting into a double of the value 6. It would be interesting to think what would happen if we tried to convert or to cast 6.7 the double 6.7 into representation of int. Int of 6.7 but then we can\u2019t really keep the value or the converted value equivalent to 6.7 because integers cannot represent a fractional part or a number a real number 6.7. So what would the compiler convert the double 6.7 to? To what integer would it be converted? So we can try it out but I will tell you what is going to happen. It is basically going to remove the fractional part and convert 6.7 to a 6 in this case. So this assigning x two equals int of 6.7 would assign the integer x two to the value of the integer 6. ",
                    "",
                    "Expressions 2.2 ",
                    "Let\u2019s take a look at another example of what happens when we mix the types. For example if we cout 5 divided by 2 so since 5 and 2 are both integers the dividing operators has the meaning of div. As we said that when slash comes between two integers that means div. If we do 5.0 divided 2.0 the dividing operator has the meaning of real division because when a dividing operator comes between two doubles it has the meaning of a real division. So the first cout would print 2 because 5 div 2 is 2. The second cout would print 2.5 because 5.0 divided by 2.0 is 2.5. What do you think would happen if we divide 5.0 by 2? When we try to divide a double by an integer. What meaning would the divider operator have in this case? Actually I don\u2019t know maybe it has the meaning of the div maybe it has the meaning of a real division or maybe it could even be an error. So it is not an error you can relax here the compiler when we have mixed types in an expression the compiler would try to resolve the issue of the mixing types and would try to make casting of the arguments to state where the two operands would be of the same type. The casting would be what we call implicit cast casting that do not lose any accuracy in this case converting an int to a double never loses any accuracy. Because every integer could be represented as a double not the other way around right not every double can be represented as an integer some accuracy can be lost. Just as when we converted 6.7 into an integer the .7 got lost there. But converting 2 to a double that is a conversion that can be done implicitly can be done without losing any accuracy. So the compiler would try to match the types of these operands 5.0 and 2 in this case casts 2 to a double and then the dividing operator would be in the meaning of real division. So this cout would also print 2.5. Another thing I want to show you here what happens if we assign x to the value of 5 divided by 2. Obviously no issue 5 and 2 are both integers the dividing operator is div in this case so 5 div 2 is 2 and x as an integer gets the value of 2. But what will happen if we assign y to 5 div 2? Y is a double right so do you think that in this case 5 divided by 2 would be 2.5 and y would get the value 2.5 or 5 div 2 5 divided by 2 would still be 2 and y would be assigned to 2. You can try it out but I will tell you what would happen. So an assignment expression has two steps in its evaluation. First step is evaluating the right hand side after we get this value the value is assigned to the variable. And the first step doesn\u2019t take into account what\u2019s the type of the variable we are going to assign the second step. The first step just evaluates the right hand side in this case evaluating 5 divided by 2. And once again since 5 and 2 are both integers the dividing comes in a form of div. So when we are evaluating the right hand side here 5 divided by 2 would result to 2 the integer 2. But then we are trying to assign the integer 2 to the variable of type double formally we should have casted the integer 2 to a double but the compiler would do it for us so y would get the double of the value 2. What we would like to write as the literal 2.0. So y would be the double 2 in this case."
                ]
            }
        ]
    },
    {
        "module_number": 4,
        "module_name": "Data Types and Expressions Part 3",
        "file_name": "Module 4 Data Types and Expressions Part 3.docx",
        "transcript": [
            {
                "title": "Float and Double Data Types 1.7",
                "data": [
                    "  ",
                    "What\u2019s my ASCII Value? Implementation 1.4 ",
                    "Ok so let\u2019s go ahead and implement this program. First we need to ask the user for a character so cout please enter a character break the line. Then we should read this character for that let\u2019s declare a char variable. Input char and let\u2019s cin into this character this variable. Ok now we should basically convert this character to its ASCII value. For that let\u2019s have an integer to store this ASCII value and declare a variable name ASCII value. Basically I should assign this variable ASCII value with a ASCII of the input char. But if we think about it the input char variable basically contains the ASCII value in the memory so when the user enter a character in the keyboard it was translated by the compiler from its letter representation to its ASCII value. So basically we should say take the number stored in the character variable and copy it and translate it into an int variable. This way the since it will be inside an int variable it would be considered as a number and not as a character. So we should say something like ASCII value equals input char. Basically saying take the data from this variable which physically is a number and store it in this variable here which is an integer. So we can make this assignment just as is this assignment would create an implicit cast that would translate the char into an int and this cast is basically an implicit cast because it doesn\u2019t lose any accuracy. In a char there is only 256 different values and all of them can be store with exactly the same value in an int variable. But just more formal we can say cast it into int. So take this input char cast it to an int and this int value this entire int value is stored in the ASCII value character. After we do that what we have left to do is announce it to the user so cout the ASCII value of and then let\u2019s have the input char printed is and then let\u2019s write the ASCII value. So when we print let\u2019s break the line. When we print character even though inside the memory there is a number the compiler knows to print the textual representation of this number. The letter that corresponds to this number by the ASCII table so this cout would print the letter or the character that the user entered and here since ASCII value is int cout would print the integer value. It would print it as a number in this case. So this should be fine let\u2019s try to execute it and make sure it all works as we expect it to. So ok please enter a character let\u2019s put upper case T and then it says the ASCII value of upper case T  is 84 just as we expected. ",
                    "",
                    "Char Literals 1.5 ",
                    "Ok so we have the char data type for representing a character. Each character takes one byte of memory and we use the ASCII table in order to map letters into numbers. Let\u2019s see what built in literals there are in C++ for characters. So let\u2019s say we have a char variable ch and we want to assign A into this character. So obviously we cannot say something like ch equals A because the compiler would then try to assign would consider A to be a variable name and to assign the value of the variable A into the variable ch. In this case there is no variable A and that would result with a compilation error but there is another way to have a constant a literal of a value A in C++. We don\u2019t just write the letter A. For that we have the letter or each symbol enclose in a single quote. So we have single quote A single quote that is the constant or the literal for the letter A. Single quote upper case B single quote that would be a constant for the letter upper case B. And for the digits and for other symbols as well. So if we want to assign ch with a letter A we have it by ch equals and then A inside single quote. We can then cout this A and we can cout the literal itself cout quote B. We cannot by the way do ch equals double quotes A. The double quotes is for strings not for characters and that kind of assignment is totally illegal. So you can\u2019t do ch equal double quote A. There is a very big difference between character and string we will talk about the string data type in a few minutes. Ok so we have these literals what should we do if we want to have a character contain a value that cannot be printed or doesn\u2019t have a key on the keyboard. Or even if it does have a key on the keyboard we don\u2019t want to type it because it is like used for something else. For example if I want the character to be new line obviously I cannot do quote press enter and  then another quote because pressing enter would just break the line in our code. So there should be another way to say to the compiler we want to represent a new line character. For that we use a special syntax named escape character which is back slash symbol. So we do it like that we have a single quote and then in the these two single quotes write back slash n. Basically telling the compiler it is not the letter N we don\u2019t want to represent the letter N now. The back slash and the n come together to represent a single character in the case of back slash n it represents the new line character. So we can have a character ch and then assign or in this case we can just print cout and back slash N. That would break the line. Equivalent by the way to cout endl same thing they both do. So we can assign ch with back slash n and then print this ch. We can also cout the string ABC and continue printing back slash n just like cout ABC and breaking the line. By the way a cool thing we can also do cout and then inside a string inside double quotes we can have ABC back slash N that would also print ABC and break the line. So the compiler knows that A is the first character in the string B is the second character in the string C is the third character in the string and then back slash since it starts with a back slash they come together and they represent new line character. So that would also print ABC and break the line. A few other back slashes a few other characters that have this escape character that uses escape character syntax. There is also a back slash T for tab and if we want to print or to use the back slash symbol itself we just do back slash back slash. There are a few more but I think that\u2019s enough for the start. Let\u2019s talk about the arithmetic operators in context of char. Now typically arithmetic operators are used for numeric types but then characters are considered to be numeric types in this sense. And there are arithmetic operators for characters as well. For example we can add in context of characters. If we think about it it doesn\u2019t have a lot of sense to add I don\u2019t know A and W or to add C and the dollar sign. But taking a look at the ASCII table we can see that the lower case letters are all sequential and the upper case letters all come one after the other and the digit symbols also come after the other. So it would make sense to for example if we have a character A to add 1 to add an integer to the character A. Probably trying to say give the next ASCII value that comes after A so if we assign ch to be A plus 1 it would assign ch two in this case to be a B. If we print ch too it would print a B. Actually and that is kind of surprising if we cout A plus 1 I would expect it would also print a B but then if you try it out you will see that it doesn\u2019t print a B. It would print the ASCII value of B and this case it would be 98. And if we take a closer look here we will see that when we have A plus 1 A is a character 1 is an integer and when we add datas of different types if you recall in one of our previous talk we said that when we have mixed types expression one of the types is then casted to the other type in order to match the types. In this case an integer cannot be casted to a character without losing accuracy but a character can be casted to an int without losing accuracy. So A is basically casted to an int to 97 and then this 97 is added 1 and it comes to be 98. So A plus 1 is an int expression that\u2019s why it prints 98. You can take a look back at our assignment A plus 1 into ch two so A plus 1 is an int ch is a char is a character so this assignment basically has an implicit cast in it. Basically transforming translating casting the integer back to a character. If we want to make it more explicit we can for the cout for example say cout char casting of A plus 1. Basically saying transform cast translate this A plus 1 integer 98 back to a character that would print the character representation of 98 that would print a B. A few other arithmetical operators since we can add integers to characters moving in our ASCII table we can also subtract an integer from an ASCII value from a character. Basically again moving inside our ASCII table we can assign obviously characters as we have seen. ",
                    "",
                    "Convert to UPPER CASE 1.6 ",
                    "Ok so let\u2019s take all the syntax we\u2019ve talked about characters and implement the following program. Let\u2019s write a program that reads from the user a lower case letter and convert it to its upper case equivalent and prints the upper case letter of the lower case that was read. For example the program would start by asking the user please enter a lower case letter the user can for example enter lower case T and the program would respond by saying upper case of lower case T is upper case T. Let\u2019s try to think how we can implement this kind of behavior. So we already noticed that the lower case letters are sequential the upper case letters are sequential and the digits are all sequential. Using this property we can see that the distance from lower case T to lower case A is the same this offset is the same as the offset from upper case T to upper case A. We can then maybe calculate what is the offset of lower case T from lower case A and add the same distance the same offset to upper case A that would get us to upper case T. Let\u2019s use this observation in order to implement the program.",
                    "",
                    "Convert to UPPER CASE Implementation 1.7 ",
                    "Ok so let\u2019s implement this program. First let\u2019s ask the user for the lower case letter so cout please enter a lower case letter. Let\u2019s break the line. Let\u2019s read it into a variable let\u2019s first declare it lower case letter and let\u2019s read it into this variable so cin into this variable here. And now we should convert lower case letter to upper case letter. So let\u2019s have an upper case upper case letter. Eventually the upper case letter variable would store the equivalent of the lower case letter value. But we said that we first have to calculate the offset of the lower case from lower case A. So let\u2019s have an integer variable named offset that would store this offset and offset would then be whatever the value of lower case letter is from lower case A. So I have lower case letter minutes lower case A. Now this is a character and this is a character and I want the integer value of this expression here. So subtract this two ASCII values the ASCII of let\u2019s say lower case T and ASCII of lower case A and then you would have your offset value. So for example in lower case T the ASCII value is 116 and the ASCII value of A is 97 so you subtract 116 from 97 and that value would be our offset. Now we need to add this offset to upper case A and that would be our upper case letter. So upper case letter would then just be upper case A plus this offset. That would add whatever the offset was to 65 and would get us to 84 to upper case T. Again we don\u2019t really have to do all the casting but let\u2019s cast to char this expression here which is of  type int. Once again when we add a  char to an int it would cast the char to an int first and it would add it as two integers. So let\u2019s cast it back into char and that would be our upper case letter. Let\u2019s now print the output message for some reason I spelled it uppet case letter so let\u2019s change both of the declaration and where we used it. Now that it is consisted let\u2019s cout upper case of and now we need to have the value of the lower case letter since it is a char it would print it as a letter. And then is and then the uppercase letter and break the line. I can endl or back slash n that would both work. Let\u2019s try to execute it see if we don\u2019t have any silly mistakes here. Once again please enter the lower case letter we have lower case T and then it says that the upper case of lower case T is upper case T. Very well then ",
                    "",
                    "The string Class 2.1 ",
                    "Ok so we have integers we have float and doubles we have char for a single character. The next type I want to talk about is called string. Actually the string type is not a built in type in C++. In order to use the string type we would need to include to extend our language with the string library. So before using the string type we have to pound include and then string. Just as we\u2019ve extended our language for the c math and for the iostream things that are not built in in C++ we use external libraries to use this kind of syntax. Same thing with string here since it is a very useful type it is important for me to show it to you right here in the beginning of your experience with C++. So after including this string class the data that is represented using this type is a string or a text. In a representation we won\u2019t get too much into the details maybe later modules we will talk about strings in more detail. For now all I want you to know is that strings are basically sequences of characters just characters coming up in the memory one after the other. Literals built in C++ strings again not C++ but the string library strings are quotes and then a sequence of characters. So quote double quotes ABC or double quotes this is a string back slash each of them is of type string or could be considered of type string though formally they are not. Arithmetic operators in this case there are plus and assignment. Plus is a very useful operator that basically concatenates string. Let\u2019s see a few lines of code to get the hang of this syntax. So for example if we have an int variable x a double variable y obviously we can assign x with 5 and y with 7.3. In order to create a string variable as we said first we need to include string. And then we can declare a string s variable and we can set it with a literal for example hello. So s equals double quote hello. We can then cout s that would print hello and break the line endl. We can also use the concatenation operator the plus operator to for example cout s plus the string world. So s is a string double quotes word is a string and we can add a string to a string that would concatenate the text. So we would print hello world back slash or in this case enter. We can also assign s with s plus world that would turn s instead of having text hello the string hello to have the string hello world. Then we can cout s that would print hello world. So it is a very easy syntax to use but then it is very useful because there is a lot of programs would need to communicate with humans and strings and texts are the way to do that."
                ]
            }
        ]
    },
    {
        "module_number": 4,
        "module_name": "Data Types and Expressions Part 4",
        "file_name": "Module 4 Data Types and Expressions Part 4.docx",
        "transcript": []
    },
    {
        "module_number": 5,
        "module_name": "Branching Part 1",
        "file_name": "Module 5 Branching Part 1.docx",
        "transcript": [
            {
                "title": "Let\u2019s try to write a program that reads from the user a single character and then prints what\u2019s the ASCII value that corresponds to that character. For example the program would first ask the user please enter a character the user would say upper case T and then the program would respond by saying the ASCII value of upper case T is 84.",
                "data": [
                    "So, now that we have the if-else statement let's try to implement our program here. Again, we'll read a positive integer and figure out whether it's even or odd. Let's go and implement it.",
                    "",
                    "Determining the Parity Implementation 3.4 ",
                    "So let's first prompt the user to enter a positive integer: let's print \"please enter a positive integer.\" Let's read the input, so let's have an integer user input variable and let's c-in into this user input. And now we need to figure out whether the input is even or odd and create the corresponding output message in order to determine whether a number is even or odd. Basically, we observe the remainder when we divide this number by two; if the remainder is zero it means it's even. if the remainder is one means it means it's odd. So, let's do something like if and then take user input and mod it by two, and figure out whether it's zero.",
                    "Basically if user input mod two equals zero, it means the remainder when we divide user input by two is zero that means it is even. So, in this case we need C- out something like user input is even and then else we would need to c- out that user input is odd.",
                    "So based on the value of this Boolean expression, once again it is either true or false. So if user input mod two equals zero, it would be true basically we'll print even, but if user input mod two is not zero, otherwise it should be one, then we would just print odd.",
                    "",
                    "Let's go ahead and test it. So let's enter a positive integer here: let's say seven and then it would say that seven is odd. Let's also test it with an even value: let's say sixteen and then it would say sixteen is even.",
                    "",
                    "Sequence of if vs. if-else 3.5 ",
                    "In our previous implementation, when we wanted to determine whether the input was an even or an odd number, we basically read the input and then divided it by two, looked to the remainder and checked whether it's zero or non-zero and printed even or odd respectively. We used the if else statement and it makes a lot of sense because if the remainder equals to zero, it means it's even and if it's not equal to zero, if it's not even, than it is odd. I think I said at the beginning that we can, we don't really have to use the if- else, the two-way if statement we can use of a one way if as well. ",
                    "",
                    "So, take a look at this implementation here. So, once again we read the user input and then we kind of check if user input mod two equals zero, we print even after that we check if the user input mod two equals one, we print odd. So, instead of having an if else statement, we have a sequence of two one way if statement; If user input mod two equals zero, print even, if user input mod two equals one print or C- out is odd. ",
                    "",
                    "So, first I would say that both of these versions are good, they would both work, but then when we have to choose either to implement the first or the second, I strongly for the first version of the if else. And let me try to say few things why that IF ELSE version is better than the sequence of two if. So in an if else statement, we can assure that exactly one of the bodies would be executed; if the Boolean condition is true the first body would be executed, if the Boolean expression is false then the second body would be executed. So exactly one of the bodies would be executed in an IF-else statement. We cannot say the same when we have a sequence of ifs, now in this case it would work and there is not any issue in exactly one of the bodies would be executed too, but formally or generally if we have a sequence of two IF than maybe none of the Boolean expressions would be true. In that case, nobody would be executed zero bodies would be executed. If both Boolean expressions in a sequence of IF are true then both bodies would be executed, so two bodies would be executed. And obviously if one of the Boolean expressions is true then a single body would be executed. So if we have a sequence of ifs, there could be cases where not exactly one body would be executed. That's not the same in an IF-else statement. Now if we want to express a computation, a process where we want to assure that one thing would happen, an if-else statement would be a better choice. That's why I would choose an if-else statement here in order to implement this program.",
                    "",
                    "Boolean Interpretation 3.6 ",
                    "Before we move on to another control flow, I want to give you another note regarding the syntax of an IF statement in C ++. Let's take a look at this few lines of code here. So we have our main, we have an integer variable named val assigned or initialized to zero and then we check if val equals zero we say that val is zero, otherwise we say that val is not zero. Obviously, when we execute this code I would expect it to print that value zero, because val was initialized to zero and then it would say that value zero. But you can see that we didn't use the relation operator of double equals in this case value equals equals zero so.",
                    "I'm kind of wondering what would happen whether it would be a compilation error, using an expression that is formally an arithmetic expression, it's not a Boolean expression its value is not true or false, it's not a double equal operator here, it's a single equals sign so it's basically an assignment. So in case we put an arithmetic expression inside our parenthesis, in the place of a Boolean expression in the place of our condition, I'm kind of wondering what would happen whether; first the compiler would say that this expression or this if expression is illegal, or maybe it would somehow understand and interpret this kind of an expression and would create some kind of a behavior that, I don't know, let's try to think what would happen.",
                    "",
                    "So, the first question is whether to try and figure out whether this thing is valid or invalid, is it legal or illegal in C++. So surprisingly actually I would say that this expression here this if Val equals zero do one thing else do another thing is valid in C++. And it's kind of surprising because when I defined the syntax of an if else statement, we said that in the parenthesis should come a Boolean expression and once again Val equals zero is not a Boolean expression. So, it is surprising that is a valid expression in C++ it is valid. In other programming languages the equivalent syntax would not be considered valid, for example in Java I think it's not valid in other programming languages, it's also more valid but in C++ it is valid. ",
                    "",
                    "And now let's try to guess what would be the behavior in this case. So, obviously it's not checking whether val equals zero it assigns val with the value of zero, but then we can wonder whether this assignment expression is considered to be true or false whether we would execute the IF body or would execute the ELSE body. So, if you recall what we talked about the bool data type we said that false is represented by a zero and true is represented by values that are non-zero. In this case, val equals zero is an expression that first assigns zero to val but its value is the value that was assigned in this case zero. So Val equals zero is evaluated to zero, to the integer zero, but the value is zero.",
                    "",
                    "The C++ compiler gives a Boolean interpretation even to expressions that are not Boolean expressions even two arithmetic expressions and the logic is basically the same. If the value is zero it would be considered as false, if the value is non-zero then the Boolean interpretation would be true. In this case, since Val equals zero then the Boolean interpretation of this expression is false. Therefore, the else body would be executed and we would print that val is not zero. Before we end this note I just want to advise you not to use the syntax I showed you it because sometimes we make mistakes and we want to understand the behavior of our program but obviously, it is not a good programming style. In an IF statement we want to have the condition to be a Boolean expression and not an arithmetic expression that is interpreted to a Boolean value."
                ]
            }
        ]
    },
    {
        "module_number": 5,
        "module_name": "Branching Part 2",
        "file_name": "Module 5 Branching Part 2.docx",
        "transcript": [
            {
                "title": "Determining the Parity 3.3",
                "data": [
                    "So let's implement this program first let's prompt the user to enter an expression, so please enter an expression of the form of Arg one, arg 2. Let's break the line and now let's read this expression. So it can be five point two times four whatever. So the format, basically, implies that we need two double variables, arg1 and arg2 and we would also need a comma here obviously. We would also need a character for the operator so let's have a char variable OP and now that we have all of these variables we can c-in arg 1, OP and arg 2. So if the user enters five point two times four ARG one would be five point two, OP would be the star symbol, and ARG two would be four.",
                    "",
                    "Now, we want to calculate the value of this expression. So, basically we want to figure out or depending on the value of the operator, we want to apply the corresponding operator. So we need some sort of a multi- branching statement we said we're going to use a switch for that. So we're switching over the value of the OP variable, so switch OP and then we would have a few cases. So case it is plus. We would do one thing. Case and, just one second we need to take it one tab here, and then case it is minus we would do another thing. And case it is multiplication we would do some other stuff and case it is the dividing, we would do another thing. Default, we would, I don't know let's figure it out later. ",
                    "",
                    "Okay, so let's start with the case; the user entered Plus as an operator in this case. Let's have another double variable result, res for short. So let's set res to be ARG 1 plus ARG 2. So in case we get a plus we add these values and then let's print res. Same thing for subtracting and multiplying, so let's do for subtracting. So in this case we want to subtract ARG 1 and ARG 2. In this case we want to multiply ARG one and ARG two. And in this case we would want to divide ARG one and ARG two. Default if it's not one of these operators, we would just want to say that it's an illegal expression so let's write illegal expression and break.",
                    "",
                    "Okay, so let's take a closer look here at what we have. So we're switching over the operator: in case it's plus we're adding, in case it's minus we're subtracting, in case it's a star we're multiplying, in case of the slash we're dividing. Each time we're printing the result, and the body starts here and ends here for each one of these branches. Let's try to execute it to see that we don't have any unpleasant surprises here. ",
                    "",
                    "So please enter an expression five point two times four, and we would get twenty point eight. Maybe just one thing I would add here is, maybe this kind of thing. Let's say I want to add five and zero, that would be fine. But if I want to divide five by zero, I don't want to get this; it probably stands for infinite in some other compilers it would create at runtime error. I want to be more cautious here when I divide the ARG one by ARG two, and maybe ask if ARG two is not zero then we want to do all of that, want to divide and print this value. ",
                    "Otherwise, let's just, print that it\u2019s an illegal expression again. Once again let's take care of the indentation and in the case of dividing, we check if it is legal to divide or not and break after that but see that now five divided by zero would say illegal expressions so five divided by zero is an illegal expression.",
                    "",
                    "Switch Statement \u2013 Syntactic Notes 2.4 ",
                    "Before we end this module, I want to say a few additional syntactic notes regarding switch statements. Switch statements are less powerful than the if else if else statement. Everything we can do with the switch statement, we can do with the if else if else statement but not the other way around. There are stuff that we can implement using the multi- way if that are not possible to implement using switch statements.",
                    "Basically that's because the if else if, or the condition in an IF statement can be a very complex Boolean expression, where in the switch statement we're only comparing a numeric value to some constant so we can only compare equivalence of some values not more than that. But then there are cases when we do want to use switch statements, basically when we want to implement menus. When we can, when you'll get some more experience in programming, you'll see you can get the hang of whether to choose to use a switch statement over multi- way if. But before we do that, let me say some additional notes syntactic notes regarding this switch statement.",
                    "",
                    "The first thing I want to say is that the numeric expression, that comes after the switch keyword, must be of one of these three types: either an int, a char, or a bool. The numeric expression cannot be, let's say, a float or a double, cannot be more complex types that are built in or can be defined later on by programmers, it can only be one of either an int, a char, or a bool. That's a restriction we will have to live with but it's good to know that we have to create a numeric expression of one of these types. ",
                    "",
                    "The next thing we want to make explicit here, is that the case labels, these constants with we set case constant one, case constant two, and so on must be constants. It's not a coincidence that we named it constant one constant two and so on there are really constants. So basically means there are either C++ literals of type int, char, or bool or named constants basically constants, we as programmer defines constant X. equals whatever. But if they cannot be expressions, four plus five, we can do case four plus five. It cannot be using variable names, we cannot define int N and then say case N. So the case labels must be constants; that's another restriction you must follow when you use switch statements. ",
                    "",
                    "The next thing I want to note here is, when we reach a switch statement we first evaluate the numeric expression and then we start comparing it to the different constants in the case clauses. So if no case label matches the value of the numeric expression, the control branches to the default label and these expressions are basically executed, we've already said that. But what I want to add now is that the default is not, doesn't really have to appear there, if there is no different branch then nothing basically is executed inside the switch statement and the program just continues to move on. So in case the numeric expression doesn't match either one of the constants in the case branches and there is no default branch, then in this case the program just continues on. ",
                    "",
                    "The last thing I want to say is that the break keyword also is not mandatory. We don't really need to have a break statement. If we have, let's say case constant one and then some expression we said that the break basically says this is where the execution should stop and breaks out of the switch statement. But if there is no break statement after these few statements then the control basically falls through the next case, even though the constant doesn't match the expressions would be executed till we reach the next break statement. Again try to avoid needing break statements, but just in case you by mistake do that that is how the execution is going to behave.",
                    "",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 6,
        "module_name": "Loops",
        "file_name": "Module 6 Loops.docx",
        "transcript": [
            {
                "title": "Motivation 1.2",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "While Loops 2.1",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Solve Let\u2019s Count Program (using While) 2.2",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "For Loops 3.1",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Counting & Summing Digits 4.1",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Computing the Average Screen Share 5.2",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Computing the Average 5.3",
                "data": [
                    "Ok so let\u2019s implement this program here. So first let\u2019s tell the user the instructions so cout enter the grades separated by space. Let\u2019s have it in two separated lines. So let\u2019s end one line here and now let\u2019s just tell the user enter the sequence by typing negative one and break the line. Ok so now we should start reading the numbers and adding them and counting them. So we would have as we said a while loop right. But in order to control this while loop we said we are going to use flag which is a Boolean variable. We won\u2019t name it flag. Let\u2019s try to find a name that more represents what this flag basically stores. Let\u2019s name this flag maybe seen end of input. When you choose a name for a flag or for a Boolean variable I think it is a good practice to choose a name that you want to respond by saying yes or no. Seen end of input is either yes or no true or false. So that\u2019s a reasonable name for a flag. We said we have to initialize seen end of input to false. And basically we want to keep on repeating the statements in the while loop while seen end of input is still false. When it turns to true we want to break out. So this is basically the structure of our program here. We just need here to read the input add it count it. Read add count and so on. In order to accumulate the sum and the amount of numbers we would use two variables. One for the sum and one for number of students. We would need to initialize both of them before we start iterating. So sum would be initialized to 0 and number of students would also be initialized to 0. And then we should just each iteration read the current input let\u2019s just declare current. And we should add it and count it right. But we should be careful here because actually all the grades should be added and counted but if the input is negative one we basically want to break out of the loop. So before adding to sum and counting by incrementing number of students let\u2019s check if our current input is negative one. In this case double equal obviously. In this case what we want to do is raise the flag. So seen end of input equals true. And if it is not if it is not negative one only then we want to accumulate it into sum and number of students. So sum plus equals our current input and number of students should just increase. So taking a second look here we first initialize our accumulating variables sum and number of students. We initialize our flag to be down seen end of input false. And while our flag is down is basically read an input figure out if we want to raise the flag if it is negative one. Otherwise we accumulate the current input we add it to sum we count it as one of our valid grades. We increment number of students. So as long as our current is a grade we just accumulate it accumulate it and accumulate it. Once our current is negative one we raise the flag the Boolean condition is then checked and that makes this break out of the loop. After we do that basically we just calculate the average so just as before let\u2019s declare a double average variable and let\u2019s assign average to let\u2019s cast sum and divide it by the number of students. Once again let\u2019s cast number of students so then we get the average. Now we can announce the class average is and the value of the average variable and break the line. Let\u2019s execute it see that we didn\u2019t make any silly mistakes here ok. Enter the grades separated by space and your sequence by typing negative one. So let\u2019s say 90 87 76 89 and -1. And then the class average is 85.5 which is good. You can see that we didn\u2019t know how many numbers there were going to be. That made us choose a while loop here. That\u2019s typical when we don\u2019t know how many how long or how big is the how many times we want to repeat. That\u2019s usually when we pick when we choose a while statement. When we know the range of number of iterations we want to do then we choose a for loop just as we had in the counting program. It was a more readable more clear when we use the for loop. It was also in the first version of calculating the average when we knew we wanted to repeat number of students iterations we also chose a for loop. But when we don\u2019t know how many iterations we want to have a while loop is a better choice that what happened here. That was what happened when we calculated the sum of the digits of the number. We didn\u2019t know how many digits there were going to be so we used a while loop as long as we still have digits we want to keep on extracting the digits and adding it. So again as a rule of thumb here when you know the number of iterations you typically choose for loop. When you don\u2019t know it is more common to use a while loop.",
                    "",
                    "",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 7,
        "module_name": "Algorithm Analysis",
        "file_name": "Module 7 Algorithm Analysis.docx",
        "transcript": [
            {
                "title": "Computing the Average Screen Share 2 5.4",
                "data": [
                    "Ok so let\u2019s solve this problem. Let\u2019s implement a function isPrime that given a parameter num an integer or parameter would determine whether our num is prime or not. Basically would return a Boolean value true or false. The most straightforward solution would say just iterate over the numbers 1 through num count how many of them are factors of num. And after you do all of  that if the end you have only two factors one and num are obviously factors of num then these are the only two factors basically stating that num is prime. If you have more than two factors than you should return false and say that num is not prime. So we will iterate over the numbers and maintain some kind of divider counter something like that. So let\u2019s declare count divs as an integer set it to zero and then we will iterate from one to num. Each time we will check whether I is a factor of num basically we will check if num mod I equals zero. If we divide them and we don\u2019t have any remainder that means it is a factor. In this case we will increment this count divs counter. After we are done doing all of that for all the numbers we will just ask whether count divs equals two in that case we will return true. Otherwise we will return false. Yes so that\u2019s the straightforward solution. ",
                    "",
                    "Primality Testing: Solution 2 2.3 ",
                    "Ok so the first solution we suggested basically went over the entire range of numbers one through num. I want to suggest another an alternative implementation an alternative solution here. Where now instead of going with the entire range one through num we will go only on the first half of the range. One through num by two and we will skip iterating over the rest of the numbers. How come can we do how come are we allowed to do that? Let\u2019s take a look at a simpler example. For example if num is one hundred the factors of num are one two four five and so on. You can see that num by two which is fifty actually that\u2019s the last factor of 100 besides 100 itself. So in the case of 100 it was safe to go only on the first half of the range and skipping the second half. So it makes sense to do that kind of an algorithm. The question is is it a coincident that there aren\u2019t any dividers past 50 for 100 or can we say safely that no matter what the value of num is all the dividers are in the first half of the range and there are none dividers besides the number itself on the second half. And that\u2019s exactly what we are trying to show in order to show the correctness of this strategy. So let\u2019s try to argue that thing. So let\u2019s assume we have a divider in the second half of the range. Let k be such divider of num in the second half of the range therefore k is greater than num by two. And we will have to argue that k does not exist or maybe we should show that k basically equals to num. That\u2019s the only possible divider on the second half of the range. So let\u2019s have this k. Now let\u2019s take a look at k\u2019s complimentary divider. Let\u2019s say d is k\u2019s complimentary divider so basically it means that d times k equals num. Or in other words d is num over k. So let\u2019s take a look at what we have. So d is num over k and let\u2019s try to compare num over k to num over num by two. Now we know that k is greater than num by two so these two expressions are basically dividing num by either k or num by two. So when we are dividing num by k since k is greater than num by two the result of num by k is less than num by num a two. Right when you are dividing a number by a greater value you will result with a small amount than when you are dividing the same number with a smaller value. So altogether we can say since k is greater than num a two num a k is less than num by num by two. Simple arithmetic num by num by two would be equal to two. Altogether we get taking that thing together we see that d is less than two. Now these are complimentary divider of num specifically it means that d is a divider of num. Now a divider that is less than two that leaves us with d must equal to one right. The only divider that is less than two is one itself. So d is we had it before num over k equals one basically meaning that k equals num. That\u2019s what we wanted to show. So the only divider in the second half k was a divider in the second half is num itself. There aren\u2019t any divider in the second half. So we can feel safe iterating over the first half of the numbers and skipping the second half. That would make our algorithm faster I believe. So if we take a look at the previous implementation let\u2019s see what changes we need to do here. So basically we will still have the counter variable counting how many dividers we are going to have. But instead of ranging from one to num we will range from one to num by two. And then at the end a prime number we are not expecting to have two dividers right we are not going up to the end so num won\u2019t be tested. So a prime number would have only one divider in the first half of the range only one actually that\u2019s the only divider we are expecting for a prime number. If our num has more than one dividers it means that it is not a prime value. If count divs equals one we are going to return true otherwise we will return false. So that is it seems like a better version or a better implementation for the function isPrime. ",
                    "",
                    "",
                    "Primality Testing: Solution 3 2.4 ",
                    "Ok so far we have two solutions two versions. One iterating over the entire range from one through num. The second iterating over half of the range from one through num by two. I want to suggest another version a third version here. In this case we will iterate not on the second half we will iterate only on the first square root of num that first values. So instead of going from one through num by two we will go from one to the square root of num which is less than num by two. Let\u2019s take a look at 100 here as an example here these are the factors of 100. Now 50 is 100 by two is num by two. And the square root of 100 is less than 50 is 10. So actually when we are taking a look at these factors of 100 doesn\u2019t seem like such a great idea to go only on the first square root of num values. And to test how many to count how many of them are dividers. Because here in this case we have a few dividers that are less than the square root but not like num by two that there aren\u2019t any dividers greater than num by two. It seems like there are a few dividers that are greater than square root of num right 20 25 50 they are all dividers of 100 that are greater than the square root. So it makes me wonder whether it is a correct idea or a correct algorithm to count the dividers only in the first square root of num values. Maybe by going only in that small range we won\u2019t find any dividers and all of them are kind of in the other part or the other portion of the range. From the square root to num maybe we are missing some dividers if we go only on this partial range here. But if we think about it a bit more deeply for example for 100 so 10 is the square root we will see that each divider that is greater than the square root in this case 100 has a complimentary divider that is less than 100 in this case one. Same thing 50 is a divider greater than the square root 2 is its complimentary divider that is less than the square root. And so 25 and 4 and 20 and 5. So in some sense maybe we are skipping maybe we are not counting the entire number of dividers but going over the first part the first portion up to the square root we will find at least one divider in each complimentary pair of dividers. So makes us think that maybe it is a good idea to go only on the first square root values and count the number of dividers there. We kind of believe that if there are none dividers in the first portion there won\u2019t be any complimentary dividers in the second portion. We would obviously need to prove that generally not only for 100. And that\u2019s exactly what we are going to do right now. So the proofing technique we are going to use here is called proof by contradiction where we want to show some property let\u2019s say we want to show A. In this technique proof by contradiction in order to show that A is true we assume that A is not true kind of assume the contradiction the negation of A. We assume A is false and then we will just do some arguments and get to some universal contradiction. I don\u2019t know that one equals zero or some other thing that cannot hold. And by having a premise of A is false and getting a contradiction we will conclude that this assumption that A is not true is false. In other words that A must be true. In this example let\u2019s see how we use proof by contradiction as a proofing technique. So let\u2019s assume k and d are two complimentary dividers of num and the thing we cannot allow since we want to show that at least one in each pair is less than the square root. Our assumption would be that let\u2019s assume that both of them are not less than a square root. Or in other words both of them are greater than the square root. And we will show that that can hold we can\u2019t have two dividers two complimentary dividers that are both greater than the square root. So let\u2019s assume that it is the case here both are greater than the square root. And since we know that they are complimentary dividers we know that when we multiply them they would result to num. So num equals k times d. Now we assume that they are both greater than the square root. Basically k is greater than the square root of num and d is greater than the square root of num. Therefore when we multiply k by d we get something that is greater than the square root of num times square root of num right. K is greater than the square root d is greater than square root k times d is greater than square root times square root. Which is equal to num. Altogether when we take it we get that num is greater than num now that\u2019s absurd right. No number is greater than itself. Seven is not greater than seven. Five is not greater than five. Num greater than num that\u2019s an obvious contradiction. Which implies that our initial assumption that both of our dividers are greater than num is false. Or in other words it implies that at least one on each pair of complimentary dividers is less than the square root of num. Ok so given that now that we know that it is good enough to go only on the first portion of the range here from one to the square root. Let\u2019s see how we update our implementation so yea it is kind of straightforward. Instead of just going from one to num or from one to the num by two we will go from num to the from one to the square root of num. And in order to say that our num is a prime we are expecting to have only one divider in this range which is the number one itself. So the implementation would look something like that. ",
                    "",
                    "",
                    "Runtime Analysis 2.5 ",
                    "Ok so we suggested three different solutions to the primality testing problem. First going on the over the entire range from one through num. Second going over the half of the range from one through num by two. And the third going first from one through square root of num that portion of the range. We\u2019ve shown the correctness of all three versions. First one is obvious but the other two were needed a bit of an argument in order to be certain that they all would work for all values of num. Let\u2019s try to estimate the resources these versions require which is better than which. And let\u2019s concentrate on the running time of these three versions these three implementations. So let\u2019s try and figure out what is the running time of the first version the second version and the third version. Let\u2019s name them t1 t2 and t3. The time for version one the time for version two and the time for version three. So what can we say? Is t1 equals 354. Is t2 equals 1270? Actually I don\u2019t even think we can have a number for t1 and number for t2 and so on. Let\u2019s make a few observations of what we need to do when we are analyzing the runtime of an algorithm. So the first observation I want to note here is that the running time depends on the size of the input. So we can\u2019t say t1 equals 250 because it depends. If the input is 100 maybe it would take one amount of time. If the input is one million maybe the running time would be different. So the running time depends on the size of the input. In order to make our analysis of runtime in general we would need to parameterized the running time by the size of the input. So for example in our case of the primality testing problem the size of the input we would typically name it N. The size of the input is the input itself. So in this case N equals num. So t1 t2 and t3 are not just constants they are functions of N. So when we want to analyze the running time of these three algorithm we would analyze t1 of  N how many what\u2019s the time given a value of N. T2 of N and t3 of N. Now when we want to let\u2019s make another observation here. When we want to analyze the run time of an algorithm obviously it is a function of N. It is parameterized by N. Kind of depends what we do in the algorithm. So if we add numbers that\u2019s faster than I don\u2019t know dividing numbers. If we work with integers that\u2019s faster than working with floating points and doubles. And it is kind of a pain to take all of that things into consideration. We want to create a model that would give us an estimation and more quality kind of an estimation. For that since the running time depends on the operators we use and the types of data we are applying them on. In order to avoid all of that what we do is we ignore the machine dependent constants and basically count each primitive operation as one. So plus is counted as one and division is counted as one. We don\u2019t care if we are adding integers or floating points. Each primitive operator would be counted as one. Informally if we take these two observations together what we want to compare the number we want to give some kind of running time analysis. We try to compare the number of primitive operations the process executes as a function as its input size. Let\u2019s try to take that and use that criteria in order to analyze the running time of the first second and third versions of our primality testing algorithms. So let\u2019s try to compare the number of primitive operations each one of them does as a function of the input size.",
                    "",
                    "Runtime Analysis 2.6 ",
                    "Let\u2019s start with the first one. So t1 of N down here. Let\u2019s see t1 of N equals. So first thing we do is set coutn divs to zero that\u2019s one. Then we set I to one that\u2019s another one. And the new start iterating in this for loop. Each iteration we do five things right we compare I to num this less or equal to. We take the mod. We compare it to zero. And potentially we have two increments count divs plus plus and I plus plus. So we do these five things over and over how many times? N times. So all together it has it costs us five times N. So we set count to zero that was one. We set I to one that was another one and then 5n that\u2019s the cost of our for loop. After that we do compare count divs to two that\u2019s another primitive operation. And either return true or false. So altogether that\u2019s two additional things. All together one plus one plus 5n plus two equals 5n plus four. That would give us t1 to be 5n plus 4. Let\u2019s try to do the same for t2 the second and the third versions. So let\u2019s go over to the second version. Once again count divs is initialized to zero that\u2019s one operation. I is initialized to one that\u2019s another primitive operation. And then we have actually in this case six things that are repeated over and over. Less than we need to calculate the div that\u2019s another thing. Mod double equals and potentially two increments. That would give us six things that are repeated but the number of iterations here is not N as it was before it is N by two. So it is six times N by two. After we do that we have in the if outside of the for loop we have two additional operations. Comparison and a return of either true or false. All together that adds up to 3n plus four. So t1 was 5n plus 4 t2 is 3n plus 4. That\u2019s an improvement that\u2019s better than 5n plus 4. Let\u2019s quickly analyze the third version. Once again we start with setting count divs to zero that\u2019s one operation. I to zero that\u2019s another operation. And then we have six operations repeating over and over in our for loop. The comparison I to square root of num. The calculating of square root of num which is by the way not a primitive operation but for this analysis we will just assume it is. Mod comparison to zero and potentially two increments. That would give us six operations primitive operations that are repeated but the number of times that are repeated is not N. Not N by two but square root of N. That would add to six times square root of N. After that we have these two primitive operations in the next if statement. All together it adds up to six square root of N plus 4. So t3 of N would be six square root of N plus 4. That clearly shows that given that type of a criteria where we try to compare the number of primitive operations as a function the process executes as a function of the input size. That t3 is the fastest the lowest value and then t2 is a bit slower and t1 is the slowest of the three.",
                    "",
                    "Runtime Analysis 2.7  ",
                    "One more note I want to add here when we analyze the running time. Now we as you can see we are not measuring the running time using seconds as units. We are using them as number of primitive operations as units. There this is what we are counting. And we want to try to ignore the running time based on the computer we are running it on. So we want to ignore the hardware technology that the algorithm is ran on. Obviously if we take the a computer twice as fast our algorithm would run twice as fast. And we want to as I said before we want to make some kind of quality kind of a criteria that separates the algorithm by their quality. And for that we would try to avoid and to move aside the hardware technology. In order to do that we make what is called an asymptotic analysis that would look only on the order of growth of T of N. Not at the number of primitive operations but the number of growth of the number of primitive operations. So if informally we said that we compare the number of primitive operations executed by the process of the function of the input size. Using the asymptotic analysis we compare the asymptotic order of the number of primitive operations executed by the process of the function of the input size. Obviously you don\u2019t know what are the asymptotic order. Basically means I will talk about it in a much more formal way in a few minutes but first let me give you as a rule of thumb. T of N is three N squared plus six N minus fifteen. In order to get the asymptotic order of T of N which is in this case theta of N squared. We say asymptotic order is theta or sometimes you will hear big O of N squared. But for our conversation let\u2019s use the term theta. In order to figure out the asymptotic order of three N squared plus six N minus fifteen is theta of N squared we will do two things. We will drop lower order terms the six N minus fifteen will be dropped off. We will stick only with the high order term in this case three N squared. And we will also ignore the leading constant. The three would be ignored. So we will be left with N squared. So we say that T of N is three N squared plus six N minus fifteen but that is theta in asymptotic order of N squared. ",
                    "",
                    "Runtime Analysis 2.8 ",
                    "If we look back at our t1 t2 and t3 the number of primitive operations each one of them does as a function of the input size. And we will take or we will try to figure out the asymptotic order of these three expressions. So the first one dropping off the four and dropping the leading constant five. We will be left with theta of N. And same thing for t2 of N. Again the four is ignored and the leading constant of three is also dropped off. So we are also left with N. And for t3 we are left with the square root of N. That means that t1 and t2 are both theta of N and t3 is theta of square root of N. Now that\u2019s a bit surprising if we look at the results we got here if we are comparing not the actual expression of 5n plus four three and plus four and six square root of N plus four. But comparing their order for growth N N and square root of N if we are comparing the order of growth then we get that t1 and t2 are equivalent asymptotic speaking. That means that going the entire range or going half of the range gives us two algorithms that are considered to be equivalent to one another. Where the third algorithm where we go for the first portion of the square root of N first numbers that is asymptotically lower than N right. Square root of N is asymptotically lower than N that means that t3 of N is asymptotically better than t1 and t2 of N. ",
                    "",
                    "Order of Growth: Formal Definition 3.1 ",
                    "Ok so we said that when we are analyzing a runtime of an algorithm basically we compare the asymptotic order of the number of primitive operations as a function of the input size. So if T of N that represents the number of primitive operations is three N squared plus six N minus fifteen. In order to figure out the asymptotic order of it as a rule of thumb we said we are dropping lower terms and we are ignoring the constants and that would give us theta of N squared. Let\u2019s make the asymptotic order the definition of theta a bit more formal. So it goes something like that. Assuming we have two functions F of N and G of N that basically represents running time means it goes from positive integers to positive real numbers. We say that F of N is theta of G of N if there exists two real constants c1 and c2 and another positive integer constant named n0. Where for all N greater or equal to n0 F of N is bounded in between two multiplicands of G of N it is bounded in c1 G of N and c2 G of N. And that should be for all N greater or equal to n0. Now you should take a very close look at this definition let\u2019s try to look at it visually. So for example if you have F of N that is the function we are trying to figure out the order of right. We are trying to say F of N is theta of G of N. So assuming you have a function F of N and assuming you look at two multiplicands of G of N. One of them is four times G of N this green line here the other is a third times G of N this kind of blue line here. And let\u2019s look at this point here eight. And you can see that when you look over eight all the values of F the black line here is in between these two multiplicands of G. In between four times G and a third times G. So you have three constants here you have n0 as eight that\u2019s the position from where it is all this inequality here is true. So starting at zero F of N is less or equal to four times G of N and it is greater or equal to a third times G of N. So our c1 would be four and our c2 would be a third. So we have these three constants two multiplicands of G that bound F of N starting at a specific point in this case at eight. Therefore we can say that F of N is theta of G of N that is what this definition is trying to say. In order to argue that F is theta of G you should show that starting at this specific point starting at n0 F of N is in between two multiplicands of G. And you have to show these two or you have to give these two multiplicands these c1 and c2.",
                    "",
                    "Asymptotic Analysis Example 3.2 ",
                    "Ok let\u2019s try to use the definition we just saw the theta definition in order to show that three N squared plus six N minus fifteen is indeed theta of N squared. Now this proposition here three N squared plus six N minus fifteen is theta of N squared is follows whatever the theta definition is trying to define. So it is of the form F of N is theta of G of N. Or F of N here is three N squared plus six N minutes fifteen and our G of N here is N squared. So it is of the form F of N is theta of G of N. Let\u2019s follow the definition the theta definition in order to prove exactly that. So by the definition in order for F to be theta of G we need to show that there exists three constants c1 c2 and n0 that for all values greater or equal to n0 our F is in between c1 and c2 as multiplicands of G. So I don\u2019t know what c1 c2 and n0 are now but let\u2019s first try to figure them out or when we are proving we should first show them and appoint to them. And then we should show that they are good enough constants. So let\u2019s assume we have these constants and keep on with our proof. So we need to show that for all N greater or equal to n0 F of N is greater or equal to one constant times G of N and less or equal to another constant times G of N. So let\u2019s take a look at three N squared plus six N minus fifteen. Now three N squared plus six N minus fifteen is obviously less or equal to three N squared plus six N right we are just dropping off the negative fifteen which makes the entire expression here smaller or less than three N squared plus six N without the negative fifteen. If we want to make three N squared plus six N even greater instead of adding six N let\u2019s add six N squared. So three N squared plus six N squared is obviously even greater than three N squared plus six N and that is greater than three N squared plus six N minus fifteen. So altogether we have that three N squared minus six N minus fifteen is less or equal to nine N squared. That\u2019s one multiplicand of G of N so our c1 nine is a great choice for our c1 right. Now let\u2019s try to find c2. So let\u2019s take a look back at three N squared plus six N minus fifteen. Now I can say that three N squared plus six N minus fifteen is greater or equal to three N squared dropping off the six N minutes fifteen. But that would be true only if six N minutes fifteen is a positive value otherwise we can\u2019t just drop it. If it is a negative value it would make it smaller right. So let\u2019s see when is six N minus fifteen greater or equal to zero. So six N minus fifteen is greater or equal to zero if and only six N is greater or equal to fifteen or in other words N is greater or equal to 2.5. So we can\u2019t say that always three N plus six N minus fifteen is greater or equal to three N squared. But for values greater or equal to 2.5 that would be true. So let\u2019s take our starting position to be three let\u2019s take our n0 to be three. And for values greater or equal to three we can safely say that three N squared plus six N minus fifteen is greater or equal to three N squared. So c2 can then be three. Altogether we can say that starting at three now we have that three N squared plus six N minus fifteen is less or equal to nine squared and it is greater or equal to three N squared. So we have two multiplicands of N squared that bound this our F of N. So by definition we can conclude that three N squared plus six N minus fifteen is theta of N squared. Now when we made this proof we didn\u2019t know in the beginning what are c1 c2 n0 are going to be. We figured them out during our process of proving. After we have done that let\u2019s try now to read it over and make sure that our proof works correctly. So in order to show that our F of N is theta of G of N we take c1 to be 9 c2 to be 3 and n0 to be 3. Then for all values for all Ns greater or equal to three we have that three N squared plus six N minus fifteen is less or equal to nine N squared and it is greater or equal to three N squared therefore it is theta of N squared. So now it makes sense as we read it that we really showed that there are three such constants that have what we one of them to have to bound F of N by these two multiplicands of G.",
                    "",
                    "Runtime Analysis: Example 1 4.1 ",
                    "Ok let\u2019s try to analyze the runtime of two examples. Let\u2019s start with the first one. So let\u2019s take a look at this program here. It asks the user to enter an input N and then it has N iterations right. I iterating from one to N. Each time let\u2019s take a closer look here we are iterating from one to N printing a star and breaking the line. So N times we are printing N stars and breaking the line. N stars breaking the line. N times we are doing that. Altogether it comes to a square N by N stars here. But our question more interesting question is what is the running time of this program here? What is T of N? Right again we are analyzing the running time as the function of the input size in this case our N. So let\u2019s see. We read the input we are going to make an asymptotic analysis so we don\u2019t really need to care about each primitive operator operation because anyway it is going to be dropped off later on in the asymptotic analysis. So I am not even counting the one operation for cout and the single operation for the cin so they are both primitive operations but we are ignoring them. And then we have these nested loops here when we are analyzing running time it is the best good practice to go inside out. From the inner part of the algorithm towards the outer parts. So let\u2019s take a look at the inner loop here. So this inner for with the cout if we try to figure out how many operations we have there. So we can try and count the primitive operations assigning j to one and then each iteration we have three operations that are repeated N times and then we have a break line. But again since we want to make an asymptotic analysis here we can safely say that this body here makes theta of N operations right. So basically N times the outer loop would repeat these N operations right. So together all these executions would do N times N operations. Again asymptotically. That would make the entire runtime here asymptotically N squared right. Now it makes a lot of sense since we are viewing exactly what it is printed here. We are printing a square of N by N stars. So yea it makes sense each one of them is a one single operation so we are doing a total of N squared operations. So altogether it is theta of N squared. ",
                    "",
                    "Runtime Analysis: Example 2 4.2 ",
                    "Ok let\u2019s take a look at another example very similar to the previous one. But implementation wise you can see that the only difference is that the range we are iterating in the inner loop is not one through N but one through I. Which is written in orange here. So again we are reading N from the user and  then N times we are repeating a body of iterating from one to I and breaking the line. Printing I stars basically and breaking the line. So first iteration when I is one we are printing one star and breaking the line. Second iteration when I is two we are printing two stars and breaking the line and then three stars and breaking the line. Altogether we will print this kind of a triangle of stars. Once again let\u2019s try and analyze the running time of this algorithm so our T of N here. Now again I am ignoring the cout cin the return zero at the end I am focusing on the major part the major cost of our algorithm these two nested loops. Once again we are going to go from the inner parts to the outer parts adding them all together. In this case though we cannot say that each iteration we are doing the same exact thing. In the previous example each iteration we printed the same amount of stars. We did N operations each time so it was N times N. In this case one time we are printing one star then we are printing two stars and three stars. We can\u2019t multiply something by N. The number of operations we are doing here varies from iteration to iteration. We can say that each iteration we are doing the theta of I operations right. And then when we want to figure out what is the total number of operations we are doing here we are not multiplying I by something. We would need to add these values over the iterations the outer iterations we are doing here. So for I equals one we are doing one for I equals two we are doing two for I equals three we are doing three operations and so on up to N. In order to figure out the total number of operations here we would need to figure out what is the order of growth what is the asymptotic order of this sum here that goes from one through N. Now I guess you all know that arithmetic progression the sum of this arithmetic progression adds up to N times N plus one over two. Which is basically half N squared plus half N. And yea you can see that that is theta of N squared right. Again dropping the half N and dropping the half as the constant we are left with N squared. We can also formally prove by the definition of theta. But intuitively we can see that it is theta of N squared. Another way to view that is looking at the image that we are basically printing this triangle of stars here. Now we can see that this triangle here is half of the square right. It is half N squared so again intuitively N squared and half of N squared are only a constant apart. A factor constant apart and that would make them both be the same order of growth. The same squared order of growth. So that\u2019s a good thing to notice here. Another important thing I want you to remember memorize because we are going to use that thing a lot. And the visual image here of the triangle that is basically half of the square really demonstrates it that one plus two plus tree plus four plus so on up to N is the same order as N squared. It is half of the square. That\u2019s the result we are going to use quite a lot."
                ]
            }
        ]
    },
    {
        "module_number": 8,
        "module_name": "Functions Transcript",
        "file_name": "Module 8 Functions Transcript.docx",
        "transcript": [
            {
                "title": "k-Combinations Problem 1.2",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "k-Combinations Problem 1.3",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Calling a Function Code 1.6",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Runtime Stack Execution Model 1.8",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Runtime Stack Execution Model 1.9",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Program Implementation 1.10",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Scope of Variables Example 1.11",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Parameter Passing 2.2",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Analyze Digits Introduction 2.5",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Analyze Digits Implementation 2.6",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Solving Quadratic Equations 3.1",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Implementation 3.2",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Implementation 2 3.3",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Implementation 3 3.4",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Implementation 4",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Implementation 5 3.6",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            },
            {
                "title": "Implementation 6 3.7",
                "data": [
                    "One last thing we have to do here is just implement a linear function that is very easy. So in case we have an equation A x plus B equals zero. So basically if A is not zero we can safely say that the solution would be again move B to the other hand of the equation and divide by A so X would be negative B over A. And then we\u2019ll set out x to be x and return one real solution. In case both A and B are zero that means that all reals are solutions. In this case I\u2019ve also updated out x to be zero just as an example of A solution. And otherwise basically meaning that it is not or A is not different than zero it is zero. But it is not the case that both A and B are zeroes. So A is zero and B is not zero in this case we have zero x plus b equals zero there aren\u2019t solutions there. It\u2019s like zero x plus five equals zero. So in this case we just return no solutions.",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 9,
        "module_name": "Arrays",
        "file_name": "Module 9 Arrays.docx",
        "transcript": [
            {
                "title": "Motivation 1.2",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Computing the Average Implementation 1.3",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above The Average 1.4",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average Implementation 1.5",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Basic Properties of Arrays 2.1",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Basic Array Properties 2.2",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Syntactic Notes 2.4",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average 3.1",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average Implementation 3.2",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average Implementation 3.3",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average Implementation 3.4",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average Implementation 3.5",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            },
            {
                "title": "Above the Average Implementation 3.6",
                "data": [
                    "Okay so I want to tell you two more little things before we end this model. So first let's recap what we already know about static arrays. So we know that the elements of the array are stored continuously in the memory, we know that all of the elements are of the same type and we know that we can access them using a zero based index system, meaning that the compiler basically can figure out the address of a certain element just by knowing where the array starts, what index we're looking for and what's the size of each element in the array. By these the compiler can just figure out where each element is located. We also said that when we declare our array, we must supply its physical size as a constant. In this case int arr of size six, this six must be given at compile time. ",
                    "",
                    "I want to say two things, two more things about static arrays, two more syntactic issues that I want you to be aware of. First is that the arrays name is a legal C++ expression. Basically saying that if we create an array of, let's say, size six the name of the array ARR is legal C++ expression. We can even print the value of this expression we can do cout arr, not arr zero, one, two, obviously, but we can cout the value of the arrays name. The value of this expression, you can try to guess, but I just tell you that its value is the address in the memory where the array starts. So, if this array starts at address one thousand, this cout would just print one thousand. So that's one thing I wanted to say.",
                    "",
                    "Another thing, another syntactic feature that we have for arrays is way to initialize array. So initialization of array and this thing is only at declaration. So, typically we can create an array of size six if we want to assign it with values we just go arr zero equals five, and arr one equals seven, and so on. But I want to show you a different syntax for array initialization; we can do something like that int arr six equals and then inside curly braces, I can just list the values so I can have five, seven, six, two, I don't know, one, fifteen, whatever. That would not only create our array of size\n six but it would also initialize the elements of the array to be the ones we gave in this list here. I just have to say again, that this is valid only at declaration; we can't create let's say an array in arr six and later on do something like arr are equals, I don't know, some list of values. That is not legal. ",
                    "",
                    "Another thing I want to say here, you don't have to put a list of all of like, in this case six values. If you have less than six values, let's say if you give only three values in your list then these three values would be the first three values of the array and the rest of the array would just be filled with zeros. ",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 10,
        "module_name": "Strings",
        "file_name": "Module 10 Strings.docx",
        "transcript": [
            {
                "title": "Introduction 1.2",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Initializing & Concatenating Strings 1.3",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Reading Strings 1.4",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Indexing Strings 1.5",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Slicing Strings 1.6",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Length 1.7",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Printing Backwards Introduction 1.8",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Printing Backwards Implementation 1.9",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Comparing Strings 1.10",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "First Word Introduction 1.11",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "First Word Implementation 1.12",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            },
            {
                "title": "Searching in a String 1.13",
                "data": [
                    "So this is the syntax for the find method. We have our calling object str dot find and then an additional string we are searching for passed a parameter to the method. I want to say or tell you about an extension of the find method that in addition to the string we are searching for we also pass a starting index. Let me show you how it works. So let\u2019s go back to the example we\u2019ve talked before. If we\u2019ll search for CD and give a starting index of three. In this case the first occurrence of CD after index three would be actually the second occurrence of CD in the original string which is I think index five. Yeah that\u2019s what it basically prints. So the extended version searches for s but starts not at the beginning but at whatever starting index we give it. And gives us the first occurrence of the s after that position."
                ]
            }
        ]
    },
    {
        "module_number": 11,
        "module_name": "Pointers and Dynamic Storage Script",
        "file_name": "Module 11 Pointers and Dynamic Storage Script.docx",
        "transcript": [
            {
                "title": "Introduction 1.2",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Pointers \u2013 Why? 1.3",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "What It Looks Like 1.4",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Getting Pointers to Point 1.5",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Accessing Data From a Pointer 1.6",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "What if a pointer doesn\u2019t point to anything? 1.7",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Defining Multiple Pointers 1.8",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Let\u2019s Get Dynamic 1.9",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Well, That\u2019s New 1.10",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "For every new, there must be delete 1.11",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "What About Arrays 1.12",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "What can we do with heap-dynamic arrays? 1.13",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Pointer Arithmetic 1.14",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "A Real Example of a Growing Array 1.15",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "Someone\u2019s Done This Already 1.16",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            },
            {
                "title": "But Wait\u2026 There\u2019s More! 1.17",
                "data": [
                    "So we covered a lot of material in this module we covered pointers and we covered how to make a pointer point to something how to get the address of a variable how to access information via a pointer. We also talked about heap dynamic variables and heap dynamic arrays. We talked about vectors and we talked about the range for loops we covered a lot of material and this does take quite a bit of time to acclimate to using heap dynamic variables and making sure that we don't have memory leaks and making sure that we don't have double deletes. But we'll get used to them over the course of the semester and you'll be experts by the end."
                ]
            }
        ]
    },
    {
        "module_number": 12,
        "module_name": "Recursions and Mathematical Induction",
        "file_name": "Module 12 Recursions and Mathematical Induction.docx",
        "transcript": [
            {
                "title": "Conclusion 1.18",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Mathematical Induction Overview 1.2",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Mathematical Induction Example 1.3",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Mathematical Induction Implementation 1.4",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Strong Induction Overview 1.5",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Strong Induction Example 1.6",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Strong Induction Example 1.7",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "What is Recursion? 1.2",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Print Ascending Problem 1.3",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Tracing printAsc with Runtime Stack 1.4",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Tracing printAsc 1.4",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "printAsc Alternative Implementations 1.6",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Print Ascending and Descending 1.7",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Factorial 1.2",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Factorial Implementation 1.3",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            },
            {
                "title": "Are All of the Digits Even? 1.4",
                "data": [
                    "Okay. So let's implement this function are all even so let\u2019s write first the prototype, Bool are all even, and it should get an array and it's logical size N. and let's start since we are looking for a recursive implementation, let's start with the base case. Base case we're basically trying to solve the problem for the smallest possible input. In this case the size of the problem would be the number of elements in the array.",
                    "So the more the elements are in the array the bigger the problem is, the less elements in the array the smaller the problem is the smallest. The problem can be is when there is a single element in the rate. So let's check for this case: if we have, and N basically tells us the number of elements in the array so if N equals one that identifies the smallest possible input. Now, let's have the solution for this case; let's return the right value in case that it is a single element array. So in this case we just need to check whether this single element is even or not, we can use an IF statement modding it by two and checking whether it's zero and returning true or false. We can do the same in return statement in the return line, so we can return the value of A R R zero mod two equals zero. So if when we're dividing the single element by two and the remainder is zero, then this expression here would be true and we would pass; this true is a return value. But if the remainder when we're dividing A R R zero by two would not be zero, therefore it would be one, this expression would be false and then we would return the value false. So, that these two lines of code here basically solve correctly the base case, the scenario when we have the smallest possible input. the recursive step we are supposed to give the right value, the right output for all other inputs for basically arrays that are not single element arrays. and we should use our induction assumption that make it explicit, our assumption would be if we call this function, if we call are all even, this function, with a smaller instance basically within an array of less elements in it, then it would decide correctly it will return correctly whether all of the elements in this smaller array are all even or not. In order to create a smaller instance, we can just pass logically the first and minus one elements. ",
                    "",
                    "So let's create a temp variable here: result. And let's set result to be the result of calling this function with the same starting address but logically only N minus one elements. That is obviously a smaller instance for this problem; it is an N minus one array. And given this assumption here calling the function on a smaller instance would return the appropriate value so res would be true if all of the first and N minus one elements are all even, and it would be false otherwise. So res almost has all of the values we need here; all of the result we need here. We just need to check the last element; we need to check the last element actually only in case that res is true. ",
                    "",
                    "So, let's check if res is true then we're not sure yet whether our result should be true or false; we need to figure that out. But if resists is not true, basically if res is false, if not all of the elements in this first N minus one elements of array are all even that means that obviously not all of the elements in the entire array are all even. Therefore, we should return false. So if res itself is false, if this smaller instance is already false, obviously our value should be false. Only the case where the first N minus one elements are true is the case where we need to figure out whether or were entire array is also filled up with even elements. So in this case we should just check the last element and see whether it's even or not. We should do something very similar to what we've done for the single element array, but instead of going for the first element we\u2019ll check the last element. So, we'll check whether the last element A R R in the minus one index mod two equals zero; if the remainder is zero it means the last element is even, and since all the rest of the elements are also evens we would return that true. But if the last element is not even, even though all the rest of the elements are, we would still would return the false. ",
                    "",
                    "So, it seems like this implementation here is okay. Let's write a main program to test it. First, let's declare this function and our main, Let's keep it simple; let's create an array in A R R, int A R R size 4, let's put it in a few elements, two, twenty, forty six, fourteen. And then let's just call this function. So if are all even for this array and four equals true then let\u2019s print are all even. Otherwise, let\u2019s print not all are even. We're expecting, obviously, that all of them would be even in this case. Let\u2019s try to execute it; yeah, all are even. ",
                    "",
                    "Let's change it out; you know twenty three see that it still works. Not all are even; okay, good. Seems like our implementation is fine. Let's take a final look here at this implementation, as you can see we have the base case where we solve the problem for the smallest possible input, for a single sized array. and then we have our inductive, or recursive step, where we used our assumption that calling this function on the smaller instance would do the job would return true, if the smaller instance contains only even numbers. And we combine that for our original input just by you checking for the last element whether it's even or not. And that basically is our recursive implementation for this function.",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 13,
        "module_name": "Searching",
        "file_name": "Module 13 Searching.docx",
        "transcript": [
            {
                "title": "The Searching Problem 1.2",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Searching Code Sample 1.3",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "The Sorted-Search Problem 1.4",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "The Sorted-Search Problem 1.5",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Sorted Search Implementation 1.6",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "Implementation 1.7",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            },
            {
                "title": "The Sorted-Search Problem 1.8",
                "data": [
                    "Okay. So we've seen two searching algorithms: the general search algorithm, which was linear time, and sorted search, the binary search algorithm which was a log of N time. Now obviously a theta of log N is significantly better than a theta of N, but I want to show you or give you a better intuition what's the meaning of this difference of log time versus linear time. So, you would really appreciate these kinds of algorithms: the logarithmic time algorithms. Let's try to compare the value of N versus the value of log base two of N for several values. So, for example for N equals two, log two of N would be log two of two which is one, slightly better than N, one is obviously smaller than two but doesn't seem such a big difference not something to be too happy about. Let's go on, for N equals four, I'm skipping three by the way just because I want the log of N to be integer values. So, any value between two and four, in this case three, would be somewhere in that range and you see that later on as well. So, for N equals four, log two of N is log two of two squared which is four, that equals two. So again log two of four is less than four. But again doesn't seem such a big difference; let's go on. Let's keep two eight two to the power of three; let's take a look at log two of eight. That would be log two of two to the power three, that is three again better than eight not something to get too crazy about. ",
                    "",
                    "Let's go to a larger value: two to the power of ten, around one thousand right. So one thousand on the N but log two of two to the power of N, is only ten that starts to be a greater difference here; a thousand versus ten. And let's go on, two to the power of thirty two; to the power of thirty two, that's around four point three billion. When we're taking the log two of N that would be a log two of two to the power of thirty two, that it would be thirty two. That already is quite a big difference: four point three billion versus only thirty two. So an algorithm that had to do four point three operations versus an algorithm that has to do only thirty two operations, the thirty to one would run much faster. But let's even go further; let's talk about N equals two to the power of one thousand. Now that is a huge number, it represents like the quantity of two the power of one thousand is greater than the number of the total number of practicals in the universe. So that's a huge number, obviously it would take practically infinite time for an algorithm to run, to execute two to the power of one thousand instructions. But a logarithmic algorithm, on the other end, which has two log two of two to the power of one thousand, would basically need to execute only one thousand instructions and that is less than the second.",
                    "",
                    "So a logarithmic algorithm is much faster; obviously as N grows but it's much faster than the linear one. And that's the thing to take into account where we are implementing an algorithm, if we can create a logarithmic algorithm that we would give us a much better performance than a linear one. Just you can see that a linear function, if we look at the graph of F of N equals N versus a function equals to log of N, you can see that they are both kind of growing. I don't know if you can see that log of N also grows to infinity very slow, but it also grows to infinity. If we zoom out this difference would even be more visual. Again, you can see that F of N equals N, the linear function, grows very fast where the logarithmic function actually seems very much like a constant, almost doesn't grow at all. It's kind of fascinating but it would grow to infinity eventually but very very slowly. So a logarithmic algorithm is it's a very good resource, is very good algorithm.",
                    "",
                    "",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 14,
        "module_name": "Sorting",
        "file_name": "Module 14 Sorting.docx",
        "transcript": [
            {
                "title": "Linear vs. Logarithmic 1.9",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "The Sorting Problem 1.2",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Sorting Algorithms 1.3",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Selection Sort 2.1",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Selection Sort Implementation 2.2",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Selection Sort Implementation 2.3",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Runtime Analysis 2.4",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Runtime Analysis 2.5",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Merge Sort 3.1",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Implementation 3.2",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Merge Sort 3.3",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Merge Sort Implementation 3.4",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            },
            {
                "title": "Tracing Merge Sort Execution 3.5",
                "data": [
                    "Now that we know how merge-sort works; now that we've implemented merge-sort, we've even traced the execution of merge-sort. Let\u2019s try to analyze the running time of merge-sort and try to compare it to the selection-sort, or the most basic sorting algorithm, that by the way executes in a quadratic time. I hope merge-sort will give us a better result than quadratic; otherwise it wasn\u2019t worth all the effort we gave to that. It's not as easy as it sounds to analyze this kind of an algorithm because it's not as like we had an iterative process where we just summed up the number of operations we're doing each iteration so it was all like in front of our eyes and we just needed to figure out what's the body's cost and just add more and more values to figure out the total cost of the iterative process. In the case of a recursive call, a lot of operations kind of sneak in between the calls and we need to better model the number of operations that are done during the process of executing a recursive algorithm; very common model to do that is called a recursive tree model and it works something like that. We'll try to basically show all the recursive calls and their costs, all together, so it starts like that. ",
                    "",
                    "We first have a call of an array of size N. This call has two or calls two times to a function of size N by two, each one of them calls two times to a function of size N by four, each one of them calls to N by 8 and so on; they kind of keep on splitting, here we have a lot of calls to a single element array of size one.",
                    "So this is the entire set of recursive calls and their sizes, but it's not that each call here is constant, there are calls that cost us constant amount of time but there are calls that are much more expensive. So let's try at the side of each call, each circle here, write the cost of that call: how much operations do we need to pay for that call.",
                    "",
                    "So the first one in addition to the recursive calls, we need to merge to N by two element arrays into one N element array. The merge function, I don't think we've mentioned it explicitly but it's a linear function; its cost is basically the sum of the sizes of the arrays we're trying to merge. So if we are merging two N by two arrays, the cost of merge would be N, right, the number of elements we are writing basically to the merge ARR, basically copying to our array. So the cost here of this call, in addition to the recursive calls, is another N. And each one of the N by two calls costs the merge basically N be two, so the first one costs N by two and the second course costs N by two. And each one of the N by four costs N by four, right? Basically the cost is the cost of merge and that's basically the size of the elements that we're trying to sort, that\u2019s the number of elements who are basically also trying to merge. And so on and so on til the base case; each one costs one. So in order to figure out the total cost of this execution, we need to sum up all the reds here, all the extra costs. And if we know how much all of the merge function cost together, that would be the total cost of merge-sort. It\u2019s kind of difficult to sum up all the red here but then a nice observation says that it would be easier for us to sum the reds in each level first and then if we know how much a level cost, we would be able to some all the levels sums up and that would be the total cost. It works something like that. ",
                    "",
                    "So let's try to relate the level number to the cost, the total cost of that level. In order to do that we would need two additional values that we want to relate here: that the number of calls in the level, number of circles basically, and the cost of each call in the level, a single red cost. Let's start here; so in level number, the first level, I prefer to name it level to start numbering here at zero. So at level number zero, the number of calls is one, right. There is one node at the first level. The cost of this call is N, right, and then the total cost of the first level is basically N  times one which is basically N. So the first level costs N, we can see that the first level costs N. The second level, level number one has two calls, right. There are two nodes here; each one costs N by two, therefore the total cost of the level is two times N by two which is also N. Interesting. Third level, level number two, four calls each one costs N by four, once again not surprising four times N by four that would also be N. Next level would have eight nodes, each one would cost N by eight, right, and that would also sum up to N. I have a feeling that all, each one of the levels here with sum up, would total up to N; let's try to justify it.",
                    "",
                    "So for example level number K: how many calls are we expecting there? You can see the relation here between the level number and the number of calls; it\u2019s two raised to the power of the lever number, right. Eight is two to the power of three. Four is two to the power of two. Two is two to the power of one. One is two to the power of zero. Therefore, the number of calls in level number K would be two to the power of K and the cost of each call is N over that. So it would be N over two to the power of K and then the total cost would be two to the power of K times N over two to the power of K; you can see that that is also N. So I'm kind of convinced now that not only the first four levels sum up to N, but all levels with this behaving like that also sums up to N. The big question is how many levels we have here because if we know how many levels, let's say we have thirteen levels then it's going to be thirteen times N obviously the number of levels depends on N, it's related to N, so can be just thirteen. So the big question mark is: what's the level number of the last level. Once we figure that out, we know how many times we need to multiply by N, right. Let's do that. ",
                    "",
                    "So the most obvious thing we know about the last level is that the cost of each one is one, right, because size is one and we know that the cost here should be one. If you look back at the calculations we've done in Binary search, we've already seen that the value of K where N over two to the K equals one is when K is Log of N. That means that the level number that gives us cost of one should be Log two of N which means that the number of calls in that level is two to the power of Log two of N. If you're familiar with the logarithmic rules, you know that two raised to the power of Log two of N basically equals N, so we have N calls, each one costs one that also adds up to N. Not surprisingly we've seen that; so basically we know that we have N in each level, Log N times. So the total, T of N here, is N times Log N or Log N times N. So the running time is paid theta of N Log N, which is better than N squared, N times N. We know that N times Log of N is significantly better than N times N, so N Log N merge-sort is a much preferred algorithm, sorting algorithm than for example selection-sort."
                ]
            }
        ]
    },
    {
        "module_number": 15,
        "module_name": "Object Oriented Programming Concepts Script",
        "file_name": "Module 15 Object Oriented Programming Concepts Script.docx",
        "transcript": [
            {
                "title": "In this Module 1.2",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Object Orientation 1.3",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Class vs. Object 1.4",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Encapsulation 1.5",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Creating a Class 1.6",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Enforcing Protection 1.7",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Accessors and Mutators 1.8",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Accessors and Mutators 1.9",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Other Useful Functions 1.10",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Creating and Working with an Object 1.11",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Constructors 1.12",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Constructor Parts 1.13",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "More Constructors 1.14",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "An Important Pointer 1.15",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Operator Overloading 1.16",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Operator Restrictions 1.17",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Choosing Member vs. Non-Member 1.18",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "What to Return? 1.19",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "An Odd Case 1.20",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Classes that contain Dynamic Memory 1.21",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Three Problem, Big 3 Solution 1.22",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Inheritance 1.23",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Pets and Cats 1.24",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "What if we need to override? 1.25",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "What if derived SHOULD access base\u2019s stuff? 1.26",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Polymorphism 1.27",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Virtual Functions 1.28",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "Pure Virtual 1.29",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            },
            {
                "title": "The Same Function Call results in Different Output 1.30",
                "data": [
                    "We went over a lot in this module; and I know it's like drinking from a fire hose right now. But we did talk about the definition of the object in class; we talked about the whole concept of encapsulation. We talked about creation of a class and the enforcement of protections on the class. We talked about accessors and mutators, and the const modifier. We talked about constructors and how to guarantee that they were constructed properly. We talked about using operators on classes and we talked about classes that contain dynamic memory, and then we went into inheritance and polymorphism. ",
                    "",
                    "There's a lot having to do with object orientation and the amount that you have to capture for this module is really significant, but once you kind of get your head around the whole idea that we're working with data and the functions to work on that data as a single entity, it really starts to become a little bit obvious. So I hope you are able to follow along with it and if not e-mail us with any questions. Thanks."
                ]
            }
        ]
    },
    {
        "module_number": 16,
        "module_name": "File Processing Script",
        "file_name": "Module 16 File Processing Script.docx",
        "transcript": [
            {
                "title": "Introduction 1.2",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "File Processing 1.3",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Files and Locks 1.4",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Objects 1.5",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Steps to Creating 1.6",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Passing to a Function 1.7",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Cin and Cout 1.8",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Output 1.9",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "More on Output 1.10",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Example: Creating a File and Outputting Information 1.11",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Input 1.12",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Example: Opening a File Stream Object 1.13",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Reading in Data 1.14",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "What\u2019s Valid 1.15",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Getline 1.16",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Ignore 1.17",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Example: Opening a File Stream Object 1.18",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Seekg 1.19",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Reading and Writing 1.20",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            },
            {
                "title": "Appending 1.21",
                "data": [
                    "In this module we saw how to open files for both reading in and writing out. We saw how to write out information to a file; how to read in information from a file. We talked about some of the pitfalls of opening files as well as reading in and writing out. We saw how the input operator works, specifically the three-step process of skipping leading whitespace and then reading invalid characters and then stopping when it reaches trailing whitespace. We saw the use of the getLine function, the ignore function, we saw a seekG, and we saw how we can append onto the end of the file. So at this point you should have the abilities to write into your code file processing routines so that you can bring in information directly from a file. And we can now you use very large datasets, which allow us to do quite a bit of information processing, and we don't have to worry about a user sitting there for hours typing in on the keyboard."
                ]
            }
        ]
    },
    {
        "module_number": 17,
        "module_name": "Linked Lists Script",
        "file_name": "Module 17 Linked Lists Script.docx",
        "transcript": [
            {
                "title": "In this Module 1.2",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "What is a Linked List 1.3",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Linked List Visual 1.4",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Why Do We Need Linked Lists 1.5",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Working with Templates 1.6",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Templated Classes 1.7",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Designing a Linked List Node 1.8",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Designing a Linked List 1.9",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Stopping at the End vs. Going off the End 1.10",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "Recursion in Lists 1.11",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            },
            {
                "title": "What are Linked Lists Used For 1.12",
                "data": [
                    "We covered a lot of material in this module. We\u2019ve looked at what is a linked list. We\u2019ve looked at why do we need linked lists. We also talked about templates, and templates are something that are going to keep coming up time and time again throughout the rest of the semester. And in the data structures that we're going to talk about because we never know what they the type are storing inside of a data structure. We talked about the design of a linked list and you should definitely take a look at the code that we've posted in the CPP file for this module associated with this, so take a look at that because that is very useful resource. And then we talked about what linked lists are used for and get some real world example. So going forward you should understand linked lists and you should be able to make a judgment call of whether you want to use an array or vector or a linked list because that's going to make a very big difference in terms of your performance of your program. And it's an important distinction that you should understand.",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 18,
        "module_name": "Stacks and Queues Script",
        "file_name": "Module 18 Stacks and Queues Script.docx",
        "transcript": [
            {
                "title": "Stacks and Queues \u2013 Intro 1.2",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack 1.3",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack \u2013 How it Works 1.4",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack Storage 1.5",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack Storage \u2013 Continued 1.6",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack Code 1.7",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack \u2013 What is it Used For 1.8",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Stack \u2013 What is it Used For 1.9",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue \u2013 What is it 1.11",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue \u2013 How it Works 1.12",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue Storage 1.13",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue \u2013 Continued 1.14",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue Code 1.15",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue \u2013 What is it Used For 1.16",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            },
            {
                "title": "Queue Image 1.17",
                "data": [
                    "So in this module, we took a look at the two fundamental data structures in C++ that we use stacks and cues. And we saw how they work with how they were implemented and what they're used for. Hopefully have a better understanding of how a stack works, how a queue works, and you also can produce one if you had to yourself.",
                    "Now, fortunately, of course the STL took care of all this for us so if we needed a stack we could just pounding include stack and we get stack, and if we needed a queue we could just pound include queue and we end up with a queue. And all the features are there; all the functions are there. We have to push, the pop, the enqueue and the dequeue, and you can use those without having to build it yourself. But even if you had to build yourself, you realize now that it's only a couple of lines of code and it's not really going to take much to store it. So I hope you enjoyed that module and we\u2019ll see you for the next one.",
                    "",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 19,
        "module_name": "Trees and Binary Search Trees Script",
        "file_name": "Module 19 Trees and Binary Search Trees Script.docx",
        "transcript": [
            {
                "title": "In this Module 1.2",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "What is a Tree 1.3",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Some Definitions 1.4",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Tree Storage 1.5",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Binary Search Tree 1.6",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "What we need BSTs For 1.7",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "BST Node Code 1.8",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Recursion in Trees 1.9",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Tree Traversals 1.10",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Implementation 1.11",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Level Order Traversal 1.12",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Traversal Results 1.13",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Insertion into Trees 1.14",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Removal From a Tree 1.15",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Removal, Given the Node, No Children 1.16",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Removal, Given the Node, One Child 1.17",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Removal, Given the Node, Two Children 1.18",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "When BSTs Fail 1.19",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Balanced Binary Search Trees 1.20",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "AVL Trees 1.21",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Good AVL Trees 1.22",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Bad AVL Trees 1.23",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Rotation Solutions 1.24",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Double Rotation 1.25",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            },
            {
                "title": "Red-Black Trees 1.26",
                "data": [
                    "We covered a lot of stuff in this module. We talked about the definitions for trees, we\u2019ve talk about the heights and sizes and the depths and that sort of stuff. We talked about how we can store trees in main memory; remember, we talked about the parent-child relationship, parent-multi-child relationship and then we talk about the parent-child-sibling relationship.  We talked about the design of binary search trees and what we need them for. We actually went through the binary search tree code. We talked about tree traversals: in-order, pre-order, post-order and level-order. We talked about when binary search trees fail and fall back on a linked list, and even if that doesn't happen as an actual linked list, even a portion of that could cause us to lose our big O of Log N. And then we talked about balanced binary search trees: the ATL and the red-black trees.",
                    "",
                    "So we certainly covered a lot in this module and I want you to take away the idea that trees are very popular. We come across them quite often in computer science. In fact, if you just look at the files on your on your hard drive, what you're looking at is a tree. You're looking at a regular tree; it's not a binary search tree but it is a regular tree because you do have folders inside of folders in this higher structure. But they're not difficult and they\u2019re not complex. And they are incredibly useful, certainly in the binary search tree for being able to store a large quantity of data and being able to search it in big O of Log N time. So, I hope you took away a lot of good information from this module."
                ]
            }
        ]
    },
    {
        "module_number": 20,
        "module_name": "Computer Architecture Part 1",
        "file_name": "Module 20 Computer Architecture Part 1.docx",
        "transcript": [
            {
                "title": "Computer Organization Introduction 1.2",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "A Little Bit of Background 1.3",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "A Little Bit of Background 1.4",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "A Little Bit of Background 1.5",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "A Little Bit of Background 1.6",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "What We Have Covered 1.7",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "Assembly Language (Pt.1) 2.1",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Instruction Set Architecture 2.2",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introductory Example 2.4",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introduction Example 2.6",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introductory Example 2.7",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "From Assembly to Mnemonic Format 2.9",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "Introductory Example 2.10",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "Introductory Example 2.11",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "What We Have Covered 2.12",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "Assembly Language (Pt.2) 3.1",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introductory Example 3.2",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introductory Example 3.3",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introductory Example 3.4",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS Assembly: Introductory Example 3.5",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "MIPS General Purpose Registers 3.7",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            },
            {
                "title": "Another Example 3.8",
                "data": [
                    "I have added a document on the course site that summarize the 32 MIPS general purpose register that we have discussed earlier. You guys don\u2019t have to memorize their purposes, this is just as a reference. I also added the official documentation of the MIPS64 instruction set architecture. If you guys have any questions regarding anything we discussed, don\u2019t hesitate to send me an e-mail. Thanks. "
                ]
            }
        ]
    },
    {
        "module_number": 20,
        "module_name": "Computer Architecture Part 2",
        "file_name": "Module 20 Computer Architecture Part 2.docx",
        "transcript": [
            {
                "title": "Outline 1.2",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "Instructions Covered So Far 1.3",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "Jump Instructions 1.5",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Unconditional Jump Instructions 1.7",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS Unconditional Jump Target Address 1.8",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "Let us take a look at an example of how calculate a target address for jump and link instructions. Here we have a jump, where the program counter is 4DC and the address parameter is 13B. Note that all numbers are in hexadecimal. We expand the program counter to 32 bits because the formula for func2 expects 32-bit program counters. The first and second steps are straightforward; this is because even after we do PC+4, the most significant 4 bits of the program counter are still 0.",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Conditional Branch Instructions 1.10",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Conditional Branch Target Address 1.12",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "One instruction that is strongly correlated with branch instructions is SLT or Set less than instruction. SLT uses three registers, Rd, Rs and Rt. It checks if Rs is less than Rt. If so, it sets Rd to 1. Otherwise, it sets Rd to 0",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.15",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.16",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.17",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.18",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.20",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.21",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.22",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.23",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            },
            {
                "title": "MIPS64 Branch/Jump Instruction Uses 1.24",
                "data": [
                    "We have covered branch and jump instructions, which are fundamental in all instruction set architectures. As we have seen, these instructions allow the CPU to manipulate loops, function calls, and if and else conditions. This concludes the architecture portion of the course. Next, we will start discussing computer organization to understand how the CPU is designed to execute its instructions.",
                    ""
                ]
            }
        ]
    },
    {
        "module_number": 21,
        "module_name": "Computer Organization Part 1",
        "file_name": "Module 21 Computer Organization Part 1.docx",
        "transcript": [
            {
                "title": "Topics Covered 1.25",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Outline 1.2",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "MIPS64 Instructions 1.3",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "MIPS64 Instruction Type: R-Format 1.4",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "That is correct. Since there are 32 possible labels for a register, they number of bit you need to represent a register field is log base 2 of 32, which is 5.",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "MIPS64 Instruction Type: I-Format 1.6",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "MIPS64 Instruction Type: J-Format 1.7",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Instruction Fetch 2.3",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Instruction Decode 2.4",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "For the arithmetic and logic R-format instructions, the ALU of the CPU simply performs the operation using the values of the registers Rs and Rt. Recall that during the decode step, the CPU already has Rs and Rt in A and B respectively. The only thing that is an issue is how can the ALU determine what operation to perform for that R-format instruction. Recall the second opcode or function field of the R-format instruction. The ALU has a lookup table that contains the arithmetic or logic operation to perform based on the value of the function field. So, the CPU simply sends the value of A and B registers and the value of the function field of the R-format instruction to the ALU. The latter used its table to perform the operation and stores the result in ALU Out 2.",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Instruction Execute 2.8",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "That is correct. A is a temporary register that holds the value of RS, which in our case is FFFC. 0 is a 1 bit flag that holds the result of the operation of the ALU. Since the operation for this instruction is RS minus 0, the result is not 0. Therefore, the zero flag is remaining 0.",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Instruction Memory 2.10",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "High-Level Diagram 2.11",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "High-Level Diagram 2.12",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Processor Clock Rate 3.1",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Processor Clock Rate 3.2",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Processor Performance 3.3",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Processor Performance 3.4",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Processor Pipelining 3.5",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Hazards 3.6",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Structural Hazards 3.7",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Data Hazards 3.8",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            },
            {
                "title": "Branch Hazards 3.9",
                "data": [
                    "We covered the various instruction formats of MIPS64 architecture and detailed how they are used to encode information about the operations of different instructions. We also discussed the five main stages of CPU execution and their intricacies.  Then, we covered processor pipelining, which is one of the most fundamental aspects of computer organization. We discussed the benefits of pipelining in term of throughput, the hazards they present, and the common mechanisms used to overcome these hazards."
                ]
            }
        ]
    },
    {
        "module_number": 21,
        "module_name": "Computer Organization Part 2",
        "file_name": "Module 21 Computer Organization Part 2.docx",
        "transcript": [
            {
                "title": "Outline 1.2",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Memory Hierarchy 1.3",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Caches 1.4",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Caches 1.5",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "DRAM and Cache Blocks 1.6",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Configuration 1.7",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Direct Map 1.9",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Fully Associativity 1.10",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "So we see how the two extremes of cache associativity work. What we want to do is to get the best from both extremes. This is where set associativity comes in. In a set associative cache, the cache is broken down into sets of N equal blocks. In the figure we have here, the cache is broken down into sets of 2 blocks. The idea is to make the cache direct-mapped with respect to the sets, but fully associative within a given set. Here is what we mean; each DRAM block can only go to a specific cache set. For example, the D RAM blocks in blue can only go the set 0 of the cache, and all D RAM blocks in yellow can only go cache set 1. In this respect, the cache is direct-mapped with respect to which set the D RAM blocks can go to. However, within a set, a D RAM block can go to any free cache block of that set. For example, with 2 blocks in each set, a blue D RAM block can go to any block that is free in set 0. Similarly, a yellow D RAM block can go to any block in set 1.",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Block Replacement Policy 1.13",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Write Policy 1.15",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "WriteBack Policy 1.16",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Addressing 1.17",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Addressing 1.18",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Usage During Execution 1.19",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            },
            {
                "title": "Cache Usage During Execution 1.20",
                "data": [
                    "We have covered memory hierarchy. We discussed the main limitations of D RAM with respect to access delay and how it can have a significant degradation on performance. To overcome this delay, we discuss how caches can be used. We highlighted the principles of temporal and spatial locality of caches and how they can be organized to keep frequently used data and instructions closer to the CPU in order to reduce access delay."
                ]
            }
        ]
    },
    {
        "module_number": 22,
        "module_name": "Intro to OS Concepts",
        "file_name": "Module 22 Intro to OS Concepts.docx",
        "transcript": [
            {
                "title": "In this Module 1.2",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "What is an OS 1.3",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "Layers of Interaction 1.4",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "What You Buy in the Store 1.5",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "The OS as a Resource Manager 1.6",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "Back in the Olden Days 1.7",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "Today\u2019s Environment 1.8",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "Monitoring Running Programs 1.9",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "OS Levels 1.10",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "The Windows Model 1.11",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "The HAL 1.12",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "Windows Device Drivers 1.13",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            },
            {
                "title": "UNIX 1.14",
                "data": [
                    "So, we covered a real basic of operating systems; think just kind of the intro stuff. We talked about what an operating system is, we looked at some history of operating system. We did talk about preemption remember that's the stopping and restarting of a program, even if it's not doesn't need to be stopped and restarted. We talked about the architecture of an operating system. We talked about a lot of things and we're going to keep going with that. And more discussions in later modules with more of that we're going to cover on operating systems, including further discussions on processes and scheduling. We're going to talk about memory management. We're going to talk about threads and concurrency issues. So, we've got a lot to go over so keep going."
                ]
            }
        ]
    },
    {
        "module_number": 23,
        "module_name": "Processes and Threads Script",
        "file_name": "Module 23 Processes and Threads Script.docx",
        "transcript": [
            {
                "title": "Introduction 1.2",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "What is a Process? 1.3",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "5 State Process Model 1.4",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Suspension 1.5",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Process Image \u2013 The PCB 1.6",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Contents of a PCB 1.7",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Modes 1.8",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Process Switching 1.9",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Threads 1.10",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "What is Where in the Multithreaded Environment? 1.11",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Reasons for Multithreading 1.12",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Performance Example 1.13",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "Thread States/Operation 1.14",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            },
            {
                "title": "What are the Downsides? 1.15",
                "data": [
                    "So, there's a lot of ways to implement threads and a lot of these are leftovers from an older era where the operating systems didn't actually support the threads, but programmers wanted to use threaded concepts inside their programs. So, the first way to implement a thread is what we know as a kernel level thread. Now this is very different from a kernel thread, and this is very different from kernel mode.",
                    "This is the concept where the operating system recognizes that a thread has been created and the operating system will create a TCB for that thread and the operating system can choose to run that thread or can choose to block that thread and all the states that go along with that thread.",
                    "",
                    "The other main way of doing this is what we know is user level thread, and this is really a leftover of a bygone era although that still very much in use today. The biggest downside of a user level thread, actually the way that a user level thread works is that the operating system doesn't recognize that the threads are in use. So, it sees this thread as a process, let's say, so let's take for example an operating system that doesn't support threads. Well how can we run threads? We can have a library of code inside of our program, which creates or simulates creating of threads and switching between these threads.",
                    "So, what would be required would be some scheduling algorithms and some ability to create new threads and destroy threads, inside a user's program. But all of this is a simulation and the operating system doesn't really know that multiple threads, if you want to call them that, are being created here. ",
                    "Instead what it does is recognize that one process is being created. And the biggest downside to that is that if any of those threads, and I use quotations, those threads cause a blocking system call then all of those threads are going to be blocked because the OP running system just sees it as a single process.",
                    "So, that's the idea behind a user level thread. The advantage of a user level thread is that you can choose to do whatever scheduling algorithm you want; you're not at the behest of the operating system. in a kernel level thread the operating system decides when your threads are going to run, but in a user level thread you, the programmer, decide when that thread is going to run and how often it's going to be run. So, you could have three threads and give priority to one of the three threads to run more frequently than the other two, and you can't do that with kernel level threads easily. ",
                    "",
                    "The hybrid approach takes benefits from each. So, the hybrid approach, which was first implemented by an operating system known as Solaris or best implemented by an operating system the Solaris, what they did was they created both kernel level threads and they created a user level thread. And they tied the two together by means of what was known as a lightweight process, and the lightweight process is simply a container. So, we can put a number of user level threads inside of a lightweight process and we can choose to run that lightweight process on one kernel level thread, so when a kernel of a thread becomes available the lightweight process runs. And all of the user level threads in that process are run according to the scheduling library of that lightweight process. So, you as the programmer would create a lightweight process; you\u2019d creates a number of user level threads. You\u2019d assign the user level threads that you wanted to run to the lightweight process, but you can create any combination of user level threads and lightweight processes. So, if you had a very important user level thread, you would create one lightweight process for that one user level thread and any time that lightweight process ran that one user level thread would be the only one running. Then you could take three other user level threads, that are not critical, and put them on one lightweight process. So that when that lightweight process runs any of the user level threads inside could run. Of course, the same downside occurs as with user level threads, if one of the user level threads in the lightweight process blocks; all of the threads in the lightweight process will be blocked. As far as thread scheduling is concerned, there's both a global scheduling algorithm that chooses to run the kernel level threads and then there's a local scheduling algorithm, which you can implement you can manage yourself as the programmer, that would choose which of the user level threads associated with that lightweight process would be chosen to run."
                ]
            }
        ]
    },
    {
        "module_number": 24,
        "module_name": "Thread Concurrency and Deadlocks Script",
        "file_name": "Module 24 Thread Concurrency and Deadlocks Script.docx",
        "transcript": [
            {
                "title": "Implementation of Threads 1.16",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Concurrency and Deadlocks 1.2",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Reminder about Threads 1.3",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Features of having Multiple Threads 1.4",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Asynchrony 1.5",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Critical Sections 1.6",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Supplier/Demand Explanation 1.7",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Steps to Producing a Problem 1.8",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Double Update/Missing Update 1.9",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Double Update/Missing Update 1.10",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Critical Sections Identified 1.11",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Mutual Exclusion Rules 1.12",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Fundamental Mutual Exclusion 1.13",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Peterson\u2019s Algorithm 1.14",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Hardware Solutions 1.15",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Semaphores 1.16",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Semaphores \u2013 How to Use Them 1.17",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Deadlocks 1.19",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "A Real Deadlock 1.20",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Deadlock Resource Types 1.21",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Items Required for a Deadlock 1.22",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Solutions for Deadlocks 1.23",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Deadlock Prevention 1.24",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Deadlock Avoidance 1.25",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Deadlock Detection 1.26",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "Dining Philosopher\u2019s Problem 1.27",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            },
            {
                "title": "The Dining Deadlock 1.28",
                "data": [
                    "We talked about a lot during this module. We talked about what threads are; we gave a little reminder about the threads. We talked about features of having multiple threads accessing multiple resources and we said that there was the possibility, of course, that we could have asynchrony. And if we do have the possibility of a synchrony, we said that we need to identify critical sections so that we can protect those critical sections using concurrency control mechanisms. And those concurrency control mechanisms that we talked about are software and hardware based. We talked about the idea of mutual exclusion using semaphores. We talked about the design of the semaphores, and how they work internally we also went into how deadlocks occur and how we can prevent deadlocks. and then we talked about the dining philosophers problem. So, we really covered a lot during this module."
                ]
            }
        ]
    },
    {
        "module_number": 25,
        "module_name": "Memory Management Script",
        "file_name": "Module 25 Memory Management Script.docx",
        "transcript": [
            {
                "title": "Conclusion 1.29",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "In This Module 1.2",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Reasons for Memory Management 1.3",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Memory Management Requirements 1.4",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Logical vs Physical Addresses 1.5",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Partitioning Strategies 1.6",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Fixed Partitioning 1.7",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Paging 1.10",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Benefits of Paging 1.11",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Converting Logical to Physical 1.12",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Segmentation 1.13",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Virtual Memory 1.14",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "What Stays? 1.15",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Benefits of VM 1.16",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Lookup Problems 1.17",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Replacement Policy 1.18",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Clock Page Replacement Algorithm 1.19",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Resident Set Management 1.20",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Controlling Page Faults by Resident Set Size 1.21",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "PFF Algorithm 1.22",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "VSWS Algorithm 1.23",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Load Control 1.24",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Shared Pages 1.25",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            },
            {
                "title": "Unix FORK Function 1.26",
                "data": [
                    "We covered a lot of material in this module, and memory management is not a simple task at all, we know that. The operating system does a lot of work for memory management. But we did cover the need for memory management and we covered the memory management requirements; we understand those requirements of protection, and relocation, logical organization, sharing, physical organization. We talked about partitioning strategies. We talked about logical versus physical addresses, and how to convert them, specifically in the paging scenario we did a lot of calculations on how it works. We talked about virtual memory. We talked about the working set strategies and the resident set strategies and we used resident set strategies to determine how we can control the load of the system, how many processes we really have running. And then we talked about shared pages and copy on write and then the magic of the Unix FORK function.",
                    "",
                    "So, we certainly covered a lot on memory management there, of course in a current and current system today's environment, there\u2019s a lot more that has to go into memory management and these are only the basics. But at least with the basics we can get started with understanding some of the more complex features, and the operating systems courses are going to cover a lot of memory management techniques that we just kind of glazed over. So, there's a lot more out there; some of it that Microsoft will even tell us about we have to find out manually. But there's at least a good basics in this module."
                ]
            }
        ]
    }
]